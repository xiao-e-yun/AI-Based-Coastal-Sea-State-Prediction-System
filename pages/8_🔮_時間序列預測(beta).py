import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots # ç¢ºä¿ make_subplots è¢«å°å…¥
import os
import itertools
from glob import glob
import json
import plotly.express as px
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error
from utils.helpers import get_station_name_from_id, initialize_session_state, load_data
from scipy.stats import pearsonr 
import plotly.io as pio 
import logging 

# --- å¼•å…¥æ–°çš„ç•°å¸¸å€¼æª¢æ¸¬åº« ---
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from scipy import stats
from statsmodels.tsa.seasonal import STL 
# --- å¼•å…¥æ–°çš„ç•°å¸¸å€¼æª¢æ¸¬åº«çµæŸ ---

# --- å˜—è©¦å°å…¥ Prophet åŠç›¸é—œåº« ---
prophet_available = False
try:
    from prophet import Prophet
    from prophet.plot import plot_plotly
    from prophet.diagnostics import cross_validation, performance_metrics 
    from sklearn.model_selection import ParameterGrid 
    prophet_available = True
    # --- ä¿®æ­£é» 3: è¨­ç½® cmdstanpy çš„æ—¥èªŒç´šåˆ¥ï¼Œæ¸›å°‘ INFO è¼¸å‡º ---
    prophet_logger = logging.getLogger('cmdstanpy')
    prophet_logger.setLevel(logging.WARNING)
except ImportError:
    st.error("éŒ¯èª¤ï¼šProphet åº«æˆ–å…¶ä¾è³´æœªå®‰è£æˆ–ç„¡æ³•è¼‰å…¥ã€‚Prophet æ¨¡å‹é æ¸¬åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨ã€‚")
    st.info("è‹¥éœ€ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè«‹åœ¨æ‚¨çš„ Python ç’°å¢ƒä¸­é‹è¡Œä»¥ä¸‹å‘½ä»¤ï¼š")
    st.code("pip install prophet scikit-learn numpy plotly scipy")
    st.warning("å°æ–¼ Prophetï¼Œå®ƒå¯èƒ½é‚„éœ€è¦åº•å±¤çš„ C++ ç·¨è­¯å™¨ (å¦‚ CmdStan)ã€‚è«‹åƒè€ƒ Prophet å®˜æ–¹æ–‡æª”é€²è¡Œå®‰è£ã€‚")


# --- å˜—è©¦å°å…¥ statsmodels åŠ pmdarima ---
statsmodels_available = False
try:
    from statsmodels.tsa.statespace.sarimax import SARIMAX
    from statsmodels.tsa.api import ExponentialSmoothing
    import pmdarima as pm # For auto_arima
    statsmodels_available = True
except ImportError:
    st.error("éŒ¯èª¤ï¼šstatsmodels æˆ– pmdarima åº«æœªå®‰è£æˆ–ç„¡æ³•è¼‰å…¥ã€‚SARIMA å’Œ ETS æ¨¡å‹é æ¸¬åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨ã€‚")
    st.info("è‹¥éœ€ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè«‹åœ¨æ‚¨çš„ Python ç’°å¢ƒä¸­é‹è¡Œä»¥ä¸‹å‘½ä»¤ï¼š")
    st.code("pip install statsmodels pmdarima")


# --- è¨­å®šé é¢ ---
st.set_page_config(
    page_title="æ™‚é–“åºåˆ—é æ¸¬ (Beta)",
    page_icon="ğŸ”®",
    layout="wide"
)
initialize_session_state()

st.title("ğŸ”® æµ·æ´‹æ•¸æ“šæ™‚é–“åºåˆ—é æ¸¬ (Beta)")
st.markdown("ä½¿ç”¨ Prophetã€SARIMA æˆ– ETS æ¨¡å‹é æ¸¬æµ·æ´‹æ•¸æ“šçš„æœªä¾†è¶¨å‹¢ã€‚")

locations = st.session_state.get('locations', [])

predictable_params_config_map = {
    col_name: info["display_zh"] for col_name, info in st.session_state.get('parameter_info', {}).items()
    if info.get("type") == "linear"
}


# --- è¼”åŠ©å‡½æ•¸ï¼šè¨ˆç®—å¸ƒæ—å¸¶ ---
def calculate_bollinger_bands(df, window=20, num_std_dev=2):
    if len(df) < window:
        return None
    
    df_temp = df.copy() 
    df_temp['MA'] = df_temp['y'].rolling(window=window).mean()
    df_temp['StdDev'] = df_temp['y'].rolling(window=window).std()
    df_temp['Upper'] = df_temp['MA'] + (df_temp['StdDev'] * num_std_dev)
    df_temp['Lower'] = df_temp['MA'] - (df_temp['StdDev'] * num_std_dev)
    return df_temp

# --- è¼”åŠ©å‡½æ•¸ï¼šæ•¸æ“šå“è³ªåˆ†æ ---
def analyze_data_quality(df_to_check, relevant_params):
    report = {}
    for param in relevant_params:
        if param not in df_to_check.columns:
            continue
        
        s = df_to_check[param]
        total_records = len(s)
        missing_count = s.isnull().sum()
        valid_count = total_records - missing_count
        
        is_numeric = pd.api.types.is_numeric_dtype(s)
        
        param_metrics = {
            'total_records': total_records,
            'valid_count': valid_count,
            'missing_count': missing_count,
            'missing_percentage': (missing_count / total_records * 100) if total_records > 0 else 0,
            'is_numeric': is_numeric
        }

        if is_numeric:
            s_numeric = s.dropna()
            param_metrics['zero_count'] = (s_numeric == 0).sum()
            param_metrics['negative_count'] = (s_numeric < 0).sum()
            
            # --- ä¿®æ­£é»ï¼šç¢ºä¿ outlier_iqr_count åœ¨ä»»ä½•æƒ…æ³ä¸‹éƒ½è¢«å®šç¾© ---
            param_metrics['outlier_iqr_count'] = 0 # å…ˆçµ¦å®šé è¨­å€¼ç‚º 0
            if not s_numeric.empty:
                Q1 = s_numeric.quantile(0.25)
                Q3 = s_numeric.quantile(0.75)
                IQR = Q3 - Q1
                
                if IQR > 0: # åªæœ‰ç•¶ IQR å¤§æ–¼ 0 æ™‚ï¼Œæ‰è¨ˆç®—ä¸Šä¸‹é™å’Œç•°å¸¸å€¼
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    param_metrics['outlier_iqr_count'] = ((s_numeric < lower_bound) | (s_numeric > upper_bound)).sum()
                # å¦‚æœ IQR <= 0ï¼Œoutlier_iqr_count å°±æœƒä¿æŒé è¨­çš„ 0ï¼Œé€™æ˜¯åˆç†çš„ã€‚
            
            param_metrics['min_val'] = s_numeric.min() if not s_numeric.empty else np.nan
            param_metrics['max_val'] = s_numeric.max() if not s_numeric.empty else np.nan
            param_metrics['mean_val'] = s_numeric.mean() if not s_numeric.empty else np.nan
            param_metrics['std_val'] = s_numeric.std() if not s_numeric.empty else np.nan
        
        report[param] = param_metrics
    return report

# --- è¼”åŠ©å‡½æ•¸ï¼šç•°å¸¸å€¼æª¢æ¸¬èˆ‡è™•ç† ---
def detect_outliers(df, param, method='iqr', iqr_multiplier=1.5, z_threshold=3, if_contamination='auto', n_neighbors=20, stl_seasonal_period_input=None, selected_freq_pandas_input='D'):
    """
    æª¢æ¸¬æ™‚é–“åºåˆ—ä¸­çš„ç•°å¸¸å€¼ã€‚
    """
    s = df[param].copy().dropna() 
    is_outlier = pd.Series(False, index=s.index)

    if s.empty:
        return pd.Series(False, index=df.index) 

    if method == 'iqr':
        Q1 = s.quantile(0.25)
        Q3 = s.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - iqr_multiplier * IQR
        upper_bound = Q3 + iqr_multiplier * IQR
        is_outlier = (s < lower_bound) | (s > upper_bound)
    elif method == 'zscore':
        if s.std() == 0: 
            is_outlier = pd.Series(False, index=s.index)
        else:
            z = np.abs(stats.zscore(s))
            is_outlier = z > z_threshold
    elif method == 'modified_zscore':
        median = s.median()
        median_abs_dev = np.median(np.abs(s - median))
        if median_abs_dev == 0: 
            is_outlier = pd.Series(False, index=s.index)
        else:
            modified_z = 0.6745 * (s - median) / median_abs_dev
            is_outlier = np.abs(modified_z) > z_threshold
    elif method == 'isolation_forest':
        if len(s) < 2:
            is_outlier = pd.Series(False, index=s.index)
        else:
            try:
                contamination_val = 'auto' if if_contamination == 'auto' else float(if_contamination)
                if_model = IsolationForest(contamination=contamination_val, random_state=42)
                if_model.fit(s.values.reshape(-1, 1))
                is_outlier = if_model.predict(s.values.reshape(-1, 1)) == -1
            except Exception as e:
                st.warning(f"Isolation Forest æª¢æ¸¬å¤±æ•—: {e}. å°‡è·³éæ­¤æ–¹æ³•ã€‚")
                is_outlier = pd.Series(False, index=s.index)
    elif method == 'lof':
        if len(s) < n_neighbors + 1:
            is_outlier = pd.Series(False, index=s.index)
        else:
            try:
                lof_model = LocalOutlierFactor(n_neighbors=n_neighbors, novelty=False) 
                is_outlier = lof_model.fit_predict(s.values.reshape(-1, 1)) == -1
            except Exception as e:
                st.warning(f"LOF æª¢æ¸¬å¤±æ•—: {e}. å°‡è·³éæ­¤æ–¹æ³•ã€‚")
                is_outlier = pd.Series(False, index=s.index)
    elif method == 'stl_residual':
        stl_seasonal_period = stl_seasonal_period_input
        if stl_seasonal_period is None or stl_seasonal_period <= 1:
            if selected_freq_pandas_input == 'h': stl_seasonal_period = 24
            elif selected_freq_pandas_input == 'D': stl_seasonal_period = 7 
            elif selected_freq_pandas_input == 'W': stl_seasonal_period = 52 
            elif selected_freq_pandas_input == 'M': stl_seasonal_period = 12
            elif selected_freq_pandas_input == 'Q': stl_seasonal_period = 4
            elif selected_freq_pandas_input == 'Y': stl_seasonal_period = 1 
            else: stl_seasonal_period = 13 
            if stl_seasonal_period <= 1 and 'seasonal' in df.columns: 
                st.warning(f"STL å­£ç¯€æ€§é€±æœŸè‡ªå‹•è¨­å®šç‚º {stl_seasonal_period}ï¼Œè‹¥æ•¸æ“šæœ‰æ˜é¡¯å­£ç¯€æ€§è«‹æª¢æŸ¥é æ¸¬é »æ¬¡æˆ–æ‰‹å‹•èª¿æ•´ã€‚")


        if len(s) < 2 * stl_seasonal_period or stl_seasonal_period <= 1:
            if stl_seasonal_period > 1: 
                st.warning(f"æ•¸æ“šé» ({len(s)}) ä¸è¶³ï¼Œç„¡æ³•é€²è¡Œ STL åˆ†è§£ (éœ€è¦è‡³å°‘ {2 * stl_seasonal_period} é»)ã€‚å°‡è·³éæ­¤æ–¹æ³•ã€‚")
            is_outlier = pd.Series(False, index=s.index)
        else:
            try:
                stl = STL(s, seasonal=stl_seasonal_period, period=stl_seasonal_period, robust=True)
                res = stl.fit()
                residual = res.resid.dropna() 
                if residual.std() == 0:
                    is_outlier = pd.Series(False, index=s.index)
                else:
                    is_outlier = np.abs(residual - residual.mean()) > z_threshold * residual.std()
            except Exception as e:
                st.warning(f"STL åˆ†è§£æª¢æ¸¬å¤±æ•—: {e}. å°‡è·³éæ­¤æ–¹æ³•ã€‚")
                is_outlier = pd.Series(False, index=s.index)

    full_outlier_series = pd.Series(False, index=df.index)
    full_outlier_series[is_outlier.index] = is_outlier
    return full_outlier_series.fillna(False)


def handle_outliers(df, param, is_outlier, strategy='replace_interpolate'):
    """
    è™•ç†æ™‚é–“åºåˆ—ä¸­çš„ç•°å¸¸å€¼ã€‚
    """
    df_processed = df.copy()
    
    if strategy == 'remove':
        df_processed = df_processed[~is_outlier].reset_index(drop=True)
    elif strategy == 'interpolate':
        df_processed.loc[is_outlier, param] = np.nan
        df_processed[param] = df_processed[param].interpolate(method='linear')
        df_processed[param] = df_processed[param].ffill().bfill()
    elif strategy == 'cap':
        Q1 = df_processed[param].quantile(0.25)
        Q3 = df_processed[param].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 3 * IQR 
        upper_bound = Q3 + 3 * IQR
        df_processed[param] = df_processed[param].clip(lower_bound, upper_bound)
    elif strategy == 'mark':
        pass 
    
    return df_processed

# --- å´é‚Šæ¬„ï¼šé æ¸¬è¨­å®šæ§åˆ¶é … ---
st.sidebar.header("æ™‚é–“åºåˆ—é æ¸¬è¨­å®š")

if not locations:
    st.sidebar.warning("è«‹åœ¨ `config.json` çš„ `STATION_COORDS` ä¸­é…ç½®æ¸¬ç«™è³‡è¨Šã€‚")
    st.stop()

selected_station = st.sidebar.selectbox("é¸æ“‡æ¸¬ç«™:", locations, key='pages_8_station', format_func=get_station_name_from_id)

# é è¼‰å…¥æ•¸æ“šä»¥å‹•æ…‹ç²å–å¯ç”¨åƒæ•¸
df_initial_check = load_data(selected_station, st.session_state.get('parameter_info', {}))

available_predictable_params_display_to_col = {}
for col_name, display_name in predictable_params_config_map.items():
    param_col_in_data = st.session_state.get('parameter_info', {}).get(col_name, {}).get("column_name_in_data", col_name).lower()
    
    if param_col_in_data in df_initial_check.columns and pd.api.types.is_numeric_dtype(df_initial_check[param_col_in_data]):
        if df_initial_check[param_col_in_data].count() > 0: 
            available_predictable_params_display_to_col[display_name] = param_col_in_data

if not available_predictable_params_display_to_col:
    st.sidebar.error("è¼‰å…¥æ•¸æ“šå¾Œï¼Œæ²’æœ‰å¯ä¾›é æ¸¬çš„æœ‰æ•ˆæ•¸å€¼å‹åƒæ•¸ã€‚è«‹æª¢æŸ¥æ•¸æ“šæ–‡ä»¶å’Œ `config.json` ä¸­çš„åƒæ•¸é…ç½®ã€‚")
    st.stop()

selected_param_display = st.sidebar.selectbox("é¸æ“‡é æ¸¬åƒæ•¸:", list(available_predictable_params_display_to_col.keys()), key='pages_8_param_display')
selected_param_col = available_predictable_params_display_to_col[selected_param_display]

param_info_original = {}
for key, val in st.session_state.get('parameter_info', {}).items():
    if val.get("column_name_in_data", key).lower() == selected_param_col:
        param_info_original = val
        break

selected_param_display_original = param_info_original.get("display_zh", selected_param_col)
param_unit = param_info_original.get("unit", "")


st.sidebar.markdown("---")
st.sidebar.subheader("é æ¸¬æ™‚é–“è¨­å®š")

prediction_frequencies = {
    "å°æ™‚ (h)": "h",
    "å¤© (D)": "D",
    "é€± (W)": "W",
    "æœˆ (M)": "M",
    "å¹´ (Y)": "Y"
}
selected_prediction_freq_display = st.sidebar.selectbox(
    "é¸æ“‡é æ¸¬é »æ¬¡:",
    list(prediction_frequencies.keys()),
    key='pages_8_prediction_frequency'
)
selected_freq_pandas = prediction_frequencies[selected_prediction_freq_display] 

forecast_period_value = st.sidebar.number_input(
    f"é æ¸¬æœªä¾†å¤šä¹… ({selected_prediction_freq_display.split(' ')[0]}):",
    min_value=1,
    max_value=365 if selected_freq_pandas == 'D' else 8760 if selected_freq_pandas == 'h' else 12, 
    value=24 if selected_freq_pandas == 'h' else 7 if selected_freq_pandas == 'D' else 1,
    step=1,
    key='pages_8_forecast_period_value'
)

# --- æ•¸æ“šè¨“ç·´æ™‚é–“ç¯„åœé¸æ“‡ ---
st.sidebar.markdown("---")
st.sidebar.subheader("è¨“ç·´æ•¸æ“šæ™‚é–“ç¯„åœ")

if not df_initial_check.empty and 'ds' in df_initial_check.columns and not df_initial_check['ds'].isnull().all():
    min_date_available = df_initial_check['ds'].min().date()
    max_date_available = df_initial_check['ds'].max().date()
else:
    min_date_available = pd.to_datetime('1990-01-01').date()
    max_date_available = pd.Timestamp.now().date()
    st.warning("ç„¡æ³•å¾è¼‰å…¥çš„æ•¸æ“šä¸­ç²å–æ™‚é–“ç¯„åœã€‚ä½¿ç”¨é è¨­æ—¥æœŸç¯„åœã€‚")

default_start_date = min_date_available
default_end_date = max_date_available

train_start_date = st.sidebar.date_input(
    "è¨“ç·´æ•¸æ“šé–‹å§‹æ—¥æœŸ:",
    value=default_start_date,
    min_value=min_date_available,
    max_value=max_date_available,
    key='pages_8_train_start_date'
)
train_end_date = st.sidebar.date_input(
    "è¨“ç·´æ•¸æ“šçµæŸæ—¥æœŸ:",
    value=default_end_date,
    min_value=min_date_available,
    max_value=max_date_available,
    key='pages_8_train_end_date'
)

if train_start_date >= train_end_date:
    st.sidebar.error("è¨“ç·´æ•¸æ“šé–‹å§‹æ—¥æœŸå¿…é ˆæ—©æ–¼çµæŸæ—¥æœŸã€‚")
    st.stop()


# --- æ•¸æ“šé è™•ç†é¸é … ---
st.sidebar.markdown("---")
st.sidebar.subheader("æ•¸æ“šé è™•ç†")
missing_value_strategy = st.sidebar.selectbox(
    "ç¼ºå¤±å€¼è™•ç†:",
    options=['å‰å‘å¡«å…… (ffill)', 'å¾Œå‘å¡«å…… (bfill)', 'ç·šæ€§æ’å€¼ (interpolate)', 'ç§»é™¤ç¼ºå¤±å€¼ (dropna)', 'ä¸è™•ç† (ä¿æŒåŸæ¨£)'],
    key='pages_8_missing_strategy'
)

# --- é€²éšç•°å¸¸å€¼è™•ç†é¸é … ---
st.sidebar.markdown("---")
st.sidebar.subheader("é€²éšç•°å¸¸å€¼è™•ç†")
outlier_method = st.sidebar.selectbox(
    "ç•°å¸¸å€¼æª¢æ¸¬æ–¹æ³•:",
    options=['ç„¡', 'iqr', 'zscore', 'modified_zscore', 'isolation_forest', 'lof', 'stl_residual'],
    index=0,
    help="é¸æ“‡ç”¨æ–¼æª¢æ¸¬ç•°å¸¸å€¼çš„æ–¹æ³•ã€‚'ç„¡'è¡¨ç¤ºä¸é€²è¡Œç•°å¸¸å€¼æª¢æ¸¬ã€‚"
)

outlier_params = {}
if outlier_method == 'iqr':
    outlier_params['iqr_multiplier'] = st.sidebar.slider("IQR å€æ•¸:", min_value=1.0, max_value=5.0, value=1.5, step=0.1, help="IQR æ–¹æ³•ä¸­ç”¨æ–¼å®šç¾©ç•°å¸¸å€¼çš„å€æ•¸ã€‚")
elif outlier_method in ['zscore', 'modified_zscore', 'stl_residual']:
    outlier_params['z_threshold'] = st.sidebar.slider("Z-score é–¾å€¼:", min_value=1.0, max_value=5.0, value=3.0, step=0.1, help="Z-score / Modified Z-score / STLæ®˜å·®æ–¹æ³•ä¸­ç”¨æ–¼å®šç¾©ç•°å¸¸å€¼çš„é–¾å€¼ã€‚")
elif outlier_method == 'isolation_forest':
    outlier_params['if_contamination'] = st.sidebar.number_input("Isolation Forest æ±¡æŸ“åº¦:", min_value=0.01, max_value=0.5, value=0.1, step=0.01, help="Isolation Forest ä¸­é æœŸç•°å¸¸å€¼çš„æ¯”ä¾‹ã€‚")
elif outlier_method == 'lof':
    outlier_params['n_neighbors'] = st.sidebar.slider("LOF é„°å±…æ•¸:", min_value=5, max_value=50, value=20, step=1, help="LOF æ–¹æ³•ä¸­ç”¨æ–¼è¨ˆç®—å±€éƒ¨å¯†åº¦çš„é„°å±…æ•¸ã€‚")


outlier_strategy = 'ç„¡'
if outlier_method != 'ç„¡':
    outlier_strategy = st.sidebar.selectbox(
        "ç•°å¸¸å€¼è™•ç†ç­–ç•¥:",
        options=['remove', 'interpolate', 'cap', 'mark'], 
        index=1, 
        help="é¸æ“‡å¦‚ä½•è™•ç†æª¢æ¸¬åˆ°çš„ç•°å¸¸å€¼ã€‚'mark'åªæ¨™è¨˜ä½†ä¸ä¿®æ”¹æ•¸æ“šã€‚"
    )


apply_smoothing = st.sidebar.checkbox("æ‡‰ç”¨æ•¸æ“šå¹³æ»‘", value=False, key='pages_8_apply_smoothing')
smoothing_window = 1

if apply_smoothing:
    smoothing_window = st.sidebar.slider("å¹³æ»‘è™•ç† (ç§»å‹•å¹³å‡è¦–çª—):", min_value=1, max_value=24, value=3, step=1,
                                         help="ç§»å‹•å¹³å‡è¦–çª—å¤§å°ï¼ˆå–®ä½èˆ‡é æ¸¬é »æ¬¡ç›¸åŒï¼‰ã€‚1 è¡¨ç¤ºä¸é€²è¡Œå¹³æ»‘è™•ç†ã€‚æ•¸å€¼è¶Šå¤§ï¼Œæ•¸æ“šè¶Šå¹³æ»‘ï¼Œä½†å¯èƒ½ä¸Ÿå¤±ç´°ç¯€ã€‚")

apply_bollinger_bands = st.sidebar.checkbox("é¡¯ç¤ºå¸ƒæ—å¸¶", value=False, key='pages_8_bollinger')
if apply_bollinger_bands:
    bb_window = st.sidebar.slider("å¸ƒæ—å¸¶çª—å£ (ç§»å‹•å¹³å‡):", min_value=5, max_value=60, value=20, step=1, key='pages_8_bb_window')
    bb_num_std = st.sidebar.slider("å¸ƒæ—å¸¶æ¨™æº–å·®å€æ•¸:", min_value=1.0, max_value=3.0, value=2.0, step=0.1, key='pages_8_bb_std')


# --- æ¨¡å‹é¸æ“‡ ---
st.sidebar.markdown("---")
st.sidebar.subheader("æ¨¡å‹é¸æ“‡èˆ‡åƒæ•¸")
model_options = []
if prophet_available:
    model_options.append("Prophet")
if statsmodels_available:
    model_options.extend(["SARIMA", "ETS"])

if not model_options:
    st.sidebar.warning("æ²’æœ‰å¯ç”¨çš„æ™‚é–“åºåˆ—æ¨¡å‹ã€‚è«‹æª¢æŸ¥å®‰è£æç¤ºã€‚")
    st.stop()

selected_model = st.sidebar.selectbox("é¸æ“‡é æ¸¬æ¨¡å‹:", model_options, key='pages_8_model_select')

# --- æ¨¡å‹é¸æ“‡æŒ‡å¼• ---
if selected_model == "Prophet":
    st.sidebar.info(
        "**Prophet**: é©ç”¨æ–¼å…·æœ‰æ˜é¡¯å­£ç¯€æ€§ï¼ˆæ¯æ—¥ã€æ¯é€±ã€æ¯å¹´ï¼‰å’Œè¶¨å‹¢è®ŠåŒ–çš„æ•¸æ“šï¼Œå°¤å…¶åœ¨æ•¸æ“šç¼ºå¤±æˆ–ç•°å¸¸å€¼è¼ƒå¤šæ™‚è¡¨ç¾è‰¯å¥½ã€‚ç”± Facebook é–‹ç™¼ã€‚"
    )
elif selected_model == "SARIMA":
    st.sidebar.info(
        "**SARIMA (Seasonal ARIMA)**: ä¸€ç¨®ç¶“å…¸çš„çµ±è¨ˆæ¨¡å‹ï¼Œé©ç”¨æ–¼å…·æœ‰å­£ç¯€æ€§è¶¨å‹¢çš„æ•¸æ“šã€‚éœ€è¦å°æ•¸æ“šçš„è‡ªç›¸é—œå’Œåè‡ªç›¸é—œç‰¹æ€§æœ‰ä¸€å®šçš„äº†è§£ä¾†æ‰‹å‹•é¸æ“‡åƒæ•¸ï¼Œæˆ–ä½¿ç”¨ Auto-ARIMA è‡ªå‹•æœå°‹ã€‚å°ç¼ºå¤±å€¼æ•æ„Ÿã€‚"
    )
elif selected_model == "ETS":
    st.sidebar.info(
        "**ETS (Exponential Smoothing)**: é€éå°èª¤å·® (Error)ã€è¶¨å‹¢ (Trend) å’Œå­£ç¯€æ€§ (Seasonality) çµ„ä»¶é€²è¡ŒæŒ‡æ•¸å¹³æ»‘ä¾†é æ¸¬ã€‚é©ç”¨æ–¼æ•¸æ“šæ¨¡å¼è¼ƒç©©å®šï¼Œå­£ç¯€æ€§æˆ–è¶¨å‹¢æ˜ç¢ºçš„å ´æ™¯ã€‚å°ç¼ºå¤±å€¼æ•æ„Ÿã€‚"
    )


# --- å®šç¾© sarima_s_options åœ¨æ¨¡å‹åƒæ•¸è¨­å®šä¹‹å‰ ---
# çµ±ä¸€ä½¿ç”¨å°å¯«é »ç‡ä»£ç¢¼
SARIMA_S_OPTIONS_MAP = {
    "å°æ™‚ (h)": 24, # æ¯å¤©24å°æ™‚
    "å¤© (D)": 7,    # æ¯é€±7å¤©
    "é€± (W)": 52,    # æ¯å¹´52é€±
    "æœˆ (M)": 12,    # æ¯å¹´12æœˆ
    "å¹´ (Y)": 1      # å¹´åº¦æ•¸æ“šï¼Œå­£ç¯€æ€§é€±æœŸé€šå¸¸ç‚º1 (è¶¨å‹¢ç‚ºä¸»)
}

# --- æ¨¡å‹ç‰¹å®šåƒæ•¸ ---
if selected_model == "Prophet":
    st.sidebar.caption("Prophet æ¨¡å‹åƒæ•¸")
    prophet_seasonality_mode = st.sidebar.selectbox(
        "å­£ç¯€æ€§æ¨¡å¼:", ["additive", "multiplicative"], key='pages_8_prophet_seasonality_mode',
        help="additive (åŠ æ€§): å­£ç¯€æ€§æˆåˆ†ç¨ç«‹æ–¼è¶¨å‹¢ã€‚multiplicative (ä¹˜æ€§): å­£ç¯€æ€§æˆåˆ†éš¨è¶¨å‹¢è®ŠåŒ–ã€‚"
    )
    prophet_changepoint_prior_scale = st.sidebar.slider(
        "è¶¨å‹¢è®Šé»å½ˆæ€§ (changepoint_prior_scale):", 0.01, 1.0, 0.05, 0.01, key='pages_8_prophet_changepoint_prior_scale',
        help="è¶Šå¤§è¡¨ç¤ºè¶¨å‹¢è¶Šéˆæ´»ï¼Œè¶Šå®¹æ˜“éæ“¬åˆã€‚è¶Šå°è¡¨ç¤ºè¶¨å‹¢è¶Šå¹³æ»‘ã€‚"
    )
    prophet_seasonality_prior_scale = st.sidebar.slider(
        "å­£ç¯€æ€§å½ˆæ€§ (seasonality_prior_scale):", 0.01, 10.0, 1.0, 0.01, key='pages_8_prophet_seasonality_prior_scale',
        help="è¶Šå¤§è¡¨ç¤ºå­£ç¯€æ€§æˆåˆ†è¶Šéˆæ´»ã€‚è¶Šå°è¡¨ç¤ºå­£ç¯€æ€§æˆåˆ†è¶Šå¹³æ»‘ã€‚"
    )
    prophet_holidays = st.sidebar.checkbox("è€ƒæ…®ç¯€å‡æ—¥å½±éŸ¿", value=False, key='pages_8_prophet_holidays')

    # Prophet è‡ªå‹•èª¿å„ªé¸é …
    if prophet_available:
        st.sidebar.markdown("---")
        st.sidebar.subheader("Prophet é€²éšèª¿å„ª")
        auto_tune_prophet = st.sidebar.checkbox(
            "è‡ªå‹•èª¿å„ª Prophet åƒæ•¸ (å¯¦é©—æ€§)",
            value=False,
            key='pages_8_auto_tune_prophet',
            help="è‡ªå‹•æœç´¢ 'changepoint_prior_scale' å’Œ 'seasonality_prior_scale' çš„æœ€ä½³çµ„åˆã€‚å¯èƒ½è€—æ™‚è¼ƒé•·ã€‚"
        )

        if auto_tune_prophet:
            st.sidebar.info("å·²å•Ÿç”¨è‡ªå‹•èª¿å„ªï¼Œä¸Šæ–¹æ‰‹å‹•è¨­å®šå°‡è¢«å¿½ç•¥ã€‚")
            st.sidebar.markdown("**èª¿å„ªç¯„åœè¨­å®š:**")
            prophet_cps_min = st.sidebar.slider("changepoint_prior_scale æœ€å°å€¼", 0.001, 0.1, 0.01, 0.001, key='prophet_cps_min')
            prophet_cps_max = st.sidebar.slider("changepoint_prior_scale æœ€å¤§å€¼", 0.1, 1.0, 0.5, 0.01, key='prophet_cps_max')
            prophet_cps_steps = st.sidebar.slider("changepoint_prior_scale æ­¥æ•¸", 2, 10, 3, key='prophet_cps_steps')

            prophet_sps_min = st.sidebar.slider("seasonality_prior_scale æœ€å°å€¼", 0.01, 1.0, 0.1, 0.01, key='prophet_sps_min')
            prophet_sps_max = st.sidebar.slider("seasonality_prior_scale æœ€å¤§å€¼", 1.0, 10.0, 5.0, 0.1, key='prophet_sps_max')
            prophet_sps_steps = st.sidebar.slider("seasonality_prior_scale æ­¥æ•¸", 2, 10, 3, key='prophet_sps_steps')

            st.sidebar.markdown("**äº¤å‰é©—è­‰è¨­å®š:**")
            initial_period = st.sidebar.number_input(
                "äº¤å‰é©—è­‰åˆå§‹è¨“ç·´æ•¸æ“šé‡ (å¤©):", min_value=30, max_value=365*3, value=180, step=30,
                help="Prophet äº¤å‰é©—è­‰çš„åˆå§‹è¨“ç·´æ•¸æ“šé‡ï¼Œå–®ä½ç‚ºå¤©ã€‚"
            )
            period_cv = st.sidebar.number_input(
                "äº¤å‰é©—è­‰æ­¥é•· (å¤©):", min_value=7, max_value=365, value=30, step=7,
                help="æ¯æ¬¡é æ¸¬ä¹‹é–“çš„é–“éš”ï¼Œå–®ä½ç‚ºå¤©ã€‚"
            )
            horizon_cv = st.sidebar.number_input(
                "äº¤å‰é©—è­‰é æ¸¬å±•æœ›æœŸ (å¤©):", min_value=1, max_value=365, value=30, step=1,
                help="æ¯æ¬¡äº¤å‰é©—è­‰é æ¸¬çš„æœªä¾†å¤©æ•¸ã€‚"
            )
        else:
            prophet_cps_min, prophet_cps_max, prophet_cps_steps = None, None, None
            prophet_sps_min, prophet_sps_max, prophet_sps_steps = None, None, None
            initial_period, period_cv, horizon_cv = None, None, None


elif selected_model == "SARIMA":
    st.sidebar.caption("SARIMA æ¨¡å‹åƒæ•¸ (p,d,q)(P,D,Q,s)")
    
    # --- æ–°å¢ï¼šè‡ªå‹•èª¿å„ªé¸é … ---
    auto_tune_sarima = st.sidebar.checkbox(
        "è‡ªå‹•èª¿å„ª SARIMA åƒæ•¸ (Auto-ARIMA)",
        value=False,
        key='pages_8_auto_tune_sarima',
        help="ä½¿ç”¨ pmdarima åº«è‡ªå‹•æœç´¢æœ€ä½³ (p,d,q)(P,D,Q,s) åƒæ•¸ã€‚æ­¤éç¨‹å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ã€‚"
    )

    if auto_tune_sarima:
        st.sidebar.info("å·²å•Ÿç”¨ Auto-ARIMAï¼Œä¸‹æ–¹æ‰‹å‹•åƒæ•¸è¨­å®šå°‡æœƒè¢«å¿½ç•¥ã€‚")
        sarima_p, sarima_d, sarima_q, sarima_P, sarima_D, sarima_Q = 0,0,0,0,0,0 
        st.sidebar.markdown(
            "Auto-ARIMA å°‡æ ¹æ“šæ•¸æ“šå’Œé æ¸¬é »æ¬¡è‡ªå‹•é¸æ“‡æœ€ä½³çš„ `(p,d,q)(P,D,Q,s)` åƒæ•¸ã€‚"
        )
    else:
        col1, col2, col3 = st.sidebar.columns(3)
        with col1:
            sarima_p = st.number_input("p:", min_value=0, max_value=5, value=1, step=1, key='pages_8_sarima_p')
            sarima_P = st.number_input("P:", min_value=0, max_value=2, value=1, step=1, key='pages_8_sarima_P')
        with col2:
            sarima_d = st.number_input("d:", min_value=0, max_value=2, value=1, step=1, key='pages_8_sarima_d')
            sarima_D = st.number_input("D:", min_value=0, max_value=1, value=0, step=1, key='pages_8_sarima_D')
        with col3:
            sarima_q = st.number_input("q:", min_value=0, max_value=5, value=0, step=1, key='pages_8_sarima_q')
            sarima_Q = st.number_input("Q:", min_value=0, max_value=2, value=0, step=1, key='pages_8_sarima_Q')
    
    sarima_s = SARIMA_S_OPTIONS_MAP.get(selected_prediction_freq_display, 0)
    if sarima_s == 0:
        st.sidebar.warning("ç•¶å‰é æ¸¬é »æ¬¡ç„¡æ³•è‡ªå‹•è¨­å®š SARIMA å­£ç¯€æ€§é€±æœŸ (s)ã€‚è«‹ç¢ºä¿é¸æ“‡ 'å°æ™‚', 'å¤©', 'é€±', 'æœˆ' æˆ– 'å¹´'ã€‚")
        st.sidebar.info("å¦‚æœæ•¸æ“šç„¡æ˜é¡¯å­£ç¯€æ€§æˆ–æ‚¨ä¸å¸Œæœ›ä½¿ç”¨å­£ç¯€æ€§æ¨¡å‹ï¼Œè«‹å°‡ D, Q è¨­ç‚º 0ã€‚")
    else:
        st.sidebar.info(f"SARIMA å­£ç¯€æ€§é€±æœŸ (s) å°‡æ ¹æ“šé æ¸¬é »æ¬¡è‡ªå‹•è¨­ç‚º: {sarima_s}")
    
elif selected_model == "ETS":
    st.sidebar.caption("ETS (Exponential Smoothing) æ¨¡å‹åƒæ•¸")
    ets_error = st.sidebar.selectbox("èª¤å·® (error):", ['add', 'mul'], key='pages_8_ets_error')
    ets_trend = st.sidebar.selectbox("è¶¨å‹¢ (trend):", ['add', 'mul', None], key='pages_8_ets_trend')
    ets_seasonal = st.sidebar.selectbox("å­£ç¯€æ€§ (seasonal):", ['add', 'mul', None], key='pages_8_ets_seasonal')
    ets_seasonal_periods = st.sidebar.number_input(
        "å­£ç¯€æ€§é€±æœŸ (seasonal_periods):",
        min_value=1,
        max_value=365,
        value=SARIMA_S_OPTIONS_MAP.get(selected_prediction_freq_display, 1), 
        step=1,
        key='pages_8_ets_seasonal_periods'
    )
    if ets_seasonal is None:
        ets_seasonal_periods = 1 
    
    # ETS è‡ªå‹•èª¿å„ªé¸é …
    if statsmodels_available:
        st.sidebar.markdown("---")
        st.sidebar.subheader("ETS é€²éšèª¿å„ª")
        auto_tune_ets = st.sidebar.checkbox(
            "è‡ªå‹•èª¿å„ª ETS åƒæ•¸ (å¯¦é©—æ€§)",
            value=False,
            key='pages_8_auto_tune_ets',
            help="è‡ªå‹•æœç´¢ 'error', 'trend', 'seasonal' çš„æœ€ä½³çµ„åˆã€‚å¯èƒ½è€—æ™‚è¼ƒé•·ã€‚"
        )

        if auto_tune_ets:
            st.sidebar.info("å·²å•Ÿç”¨è‡ªå‹•èª¿å„ªï¼Œä¸Šæ–¹æ‰‹å‹•è¨­å®šå°‡è¢«å¿½ç•¥ã€‚")
            ets_error_options_auto = st.sidebar.multiselect("Error æ¨¡å¼ (è‡ªå‹•èª¿å„ª):", ['add', 'mul'], default=['add', 'mul'], key='ets_error_auto')
            ets_trend_options_auto = st.sidebar.multiselect("Trend æ¨¡å¼ (è‡ªå‹•èª¿å„ª):", ['add', 'mul', None], default=['add', 'mul', None], key='ets_trend_auto')
            ets_seasonal_options_auto = st.sidebar.multiselect("Seasonal æ¨¡å¼ (è‡ªå‹•èª¿å„ª):", ['add', 'mul', None], default=['add', 'mul', None], key='ets_seasonal_auto')
            
            st.sidebar.info(f"è‡ªå‹•èª¿å„ªæ™‚ï¼Œå­£ç¯€æ€§é€±æœŸå°‡æ ¹æ“šé æ¸¬é »æ¬¡è‡ªå‹•è¨­ç‚º: {SARIMA_S_OPTIONS_MAP.get(selected_prediction_freq_display, 1)}")
        else:
            ets_error_options_auto, ets_trend_options_auto, ets_seasonal_options_auto = None, None, None


# --- åŸ·è¡Œé æ¸¬æŒ‰éˆ• ---
if st.sidebar.button("ğŸ”® åŸ·è¡Œé æ¸¬"):
    if (selected_model == "Prophet" and not prophet_available) or \
       ((selected_model == "SARIMA" or selected_model == "ETS") and not statsmodels_available):
        st.error(f"æ‰€é¸æ¨¡å‹ ({selected_model}) çš„å¿…è¦åº«æœªå®‰è£æˆ–ç„¡æ³•è¼‰å…¥ã€‚è«‹åƒè€ƒéŒ¯èª¤æç¤ºå®‰è£ã€‚")
        st.stop()
    
    if selected_model == "SARIMA" and auto_tune_sarima and not statsmodels_available: 
        st.error("SARIMA è‡ªå‹•èª¿å„ªåŠŸèƒ½éœ€è¦ pmdarima åº«ï¼Œä½†å®ƒæœªå®‰è£æˆ–ç„¡æ³•è¼‰å…¥ã€‚è«‹åƒè€ƒéŒ¯èª¤æç¤ºå®‰è£ã€‚")
        st.stop()

    # --- ç•°å¸¸å€¼è™•ç†å‰ç½®æª¢æŸ¥ï¼Œç¢ºä¿ç›¸é—œåº«å¯ç”¨ ---
    if outlier_method != 'ç„¡':
        try:
            if outlier_method == 'isolation_forest':
                from sklearn.ensemble import IsolationForest
            elif outlier_method == 'lof':
                from sklearn.neighbors import LocalOutlierFactor
            elif outlier_method in ['zscore', 'modified_zscore']:
                from scipy import stats
            elif outlier_method == 'stl_residual':
                from statsmodels.tsa.seasonal import STL
        except ImportError as e:
            st.error(f"éŒ¯èª¤ï¼šæ‚¨é¸æ“‡çš„ç•°å¸¸å€¼æª¢æ¸¬æ–¹æ³• '{outlier_method}' éœ€è¦é¡å¤–çš„åº«ï¼Œä½†å…¶æœªå®‰è£æˆ–ç„¡æ³•è¼‰å…¥ï¼š`{e}`ã€‚")
            st.info("è«‹é‹è¡Œ `pip install scikit-learn scipy statsmodels` å®‰è£ç¼ºå¤±çš„åº«ã€‚")
            st.stop()


    df_loaded = load_data(selected_station, st.session_state.get('parameter_info', {})) # è¼‰å…¥åŸå§‹æ•¸æ“š

    selected_station_name = get_station_name_from_id(selected_station)

    if df_loaded.empty or selected_param_col not in df_loaded.columns:
        if df_loaded.empty:
            st.error(f"æ‰€é¸æ¸¬ç«™ '{selected_station_name}' æ²’æœ‰æˆåŠŸè¼‰å…¥ä»»ä½•æ•¸æ“šã€‚")
        else:
            st.error(f"æ‰€é¸æ¸¬ç«™ '{selected_station_name}' çš„æ•¸æ“šæ–‡ä»¶ç¼ºå°‘åƒæ•¸ '{selected_param_display_original}' (åŸå§‹åˆ—å: '{selected_param_col}')ã€‚")
            st.info(f"æ•¸æ“šä¸­å¯ç”¨çš„åˆ—: {df_loaded.columns.tolist()}")
        st.stop()

    st.info(f"æ­£åœ¨å°æ¸¬ç«™ **{selected_station_name}** çš„åƒæ•¸ **{selected_param_display_original}** åŸ·è¡Œ {selected_model} é æ¸¬...")

    # --- æ•¸æ“šé è™•ç† (é–‹å§‹) ---
    df_processed = df_loaded[['ds', selected_param_col]].copy()
    df_processed.columns = ['ds', 'y']

    # `pd.to_datetime` åœ¨ `load_data` ä¸­å·²ç¶“è™•ç†éï¼Œé€™è£¡å†æ¬¡æª¢æŸ¥ä¸¦æ’åº
    df_processed['ds'] = pd.to_datetime(df_processed['ds'], errors='coerce') 
    df_processed.sort_values('ds', inplace=True)
    df_processed.dropna(subset=['ds'], inplace=True) 

    train_start_datetime = pd.to_datetime(train_start_date)
    train_end_datetime = pd.to_datetime(train_end_date) + pd.Timedelta(days=1) - pd.Timedelta(microseconds=1)

    df_processed = df_processed[
        (df_processed['ds'] >= train_start_datetime) &
        (df_processed['ds'] <= train_end_datetime)
    ].copy()

    if df_processed.empty:
        st.error(f"åœ¨é¸å®šçš„è¨“ç·´æ™‚é–“ç¯„åœ ({train_start_date} è‡³ {train_end_date}) å…§æ²’æœ‰æ‰¾åˆ°æ•¸æ“šã€‚è«‹èª¿æ•´æ™‚é–“ç¯„åœã€‚")
        st.stop()
    
    if df_processed['ds'].duplicated().any():
        st.warning("è­¦å‘Šï¼šè¨“ç·´æ•¸æ“šä¸­å­˜åœ¨é‡è¤‡çš„æ™‚é–“æˆ³ï¼Œå¯èƒ½å½±éŸ¿æ¨¡å‹è¨“ç·´ã€‚å°‡ç§»é™¤é‡è¤‡é …ã€‚")
        df_processed.drop_duplicates(subset=['ds'], keep='first', inplace=True)

    # åœ¨é‡æ¡æ¨£å‰ä¿å­˜ä¸€ä»½ç”¨æ–¼å¯è¦–åŒ–åŸå§‹æ•¸æ“šçš„å‰¯æœ¬
    df_original_for_plot_raw = df_processed.copy()


    # å° 'ds' é€²è¡Œé‡æ¡æ¨£
    df_processed = df_processed.set_index('ds').resample(selected_freq_pandas.upper()).mean().reset_index()
    df_original_for_plot_raw = df_original_for_plot_raw.set_index('ds').resample(selected_freq_pandas.upper()).mean().reset_index()
    df_original_for_plot = df_original_for_plot_raw.copy()


    # --- ç¼ºå¤±å€¼è™•ç† ---
    if missing_value_strategy == 'å‰å‘å¡«å…… (ffill)':
        df_processed['y'] = df_processed['y'].ffill()
    elif missing_value_strategy == 'å¾Œå‘å¡«å…… (bfill)':
        df_processed['y'] = df_processed['y'].bfill()
    elif missing_value_strategy == 'ç·šæ€§æ’å€¼ (interpolate)':
        df_processed['y'] = df_processed['y'].interpolate(method='linear')
    elif missing_value_strategy == 'ç§»é™¤ç¼ºå¤±å€¼ (dropna)':
        df_processed = df_processed.dropna(subset=['y'])
    elif missing_value_strategy == 'ä¸è™•ç† (ä¿æŒåŸæ¨£)':
        st.info("å·²é¸æ“‡ä¸è™•ç†ç¼ºå¤±å€¼ã€‚è«‹æ³¨æ„ï¼ŒæŸäº›æ¨¡å‹å¯èƒ½ç„¡æ³•è™•ç† NaN å€¼ã€‚")
    
    # é‡å°ç¼ºå¤±å€¼è™•ç†å¾Œæ•¸æ“šæ˜¯å¦ç‚ºç©ºé€²è¡Œæª¢æŸ¥
    if df_processed['y'].isnull().all():
        st.error(f"åœ¨ç¶“éé è™•ç†å¾Œï¼Œåƒæ•¸ '{selected_param_display}' çš„æ•¸æ“šå…¨éƒ¨ç‚ºç¼ºå¤±å€¼ã€‚ç„¡æ³•é€²è¡Œé æ¸¬ã€‚")
        st.stop()
        
    # å¦‚æœé¸æ“‡ä¸è™•ç†ï¼Œä¸¦ä¸”æ•¸æ“šä¸­ä»æœ‰ NaNï¼Œå‰‡ç™¼å‡ºè­¦å‘Š
    if missing_value_strategy == 'ä¸è™•ç† (ä¿æŒåŸæ¨£)' and df_processed['y'].isnull().any():
        st.warning(f"è­¦å‘Šï¼šæ‚¨é¸æ“‡äº†ä¸è™•ç†ç¼ºå¤±å€¼ï¼Œæ•¸æ“šä¸­ä»åŒ…å« {df_processed['y'].isnull().sum()} å€‹ç¼ºå¤±å€¼ã€‚SARIMA æˆ– ETS æ¨¡å‹å¯èƒ½å› æ­¤å¤±æ•—ã€‚")

    # --- åŸ·è¡Œç•°å¸¸å€¼æª¢æ¸¬èˆ‡è™•ç† ---
    is_outlier_series_original_detection = pd.Series(False, index=df_processed.index) 
    num_outliers = 0 
    if outlier_method != 'ç„¡':
        st.info(f"æ­£åœ¨åŸ·è¡Œç•°å¸¸å€¼æª¢æ¸¬ (æ–¹æ³•: {outlier_method}) å’Œè™•ç† (ç­–ç•¥: {outlier_strategy})...")
        
        stl_s_period_for_detection = SARIMA_S_OPTIONS_MAP.get(selected_prediction_freq_display, None)
        
        is_outlier_series_original_detection = detect_outliers(
            df_processed, 
            'y',
            method=outlier_method,
            iqr_multiplier=outlier_params.get('iqr_multiplier', 1.5),
            z_threshold=outlier_params.get('z_threshold', 3.0),
            if_contamination=outlier_params.get('if_contamination', 'auto'),
            n_neighbors=outlier_params.get('n_neighbors', 20),
            stl_seasonal_period_input=stl_s_period_for_detection, 
            selected_freq_pandas_input=selected_freq_pandas.lower() 
        )
        
        num_outliers = is_outlier_series_original_detection.sum()
        if num_outliers > 0:
            st.info(f"æª¢æ¸¬åˆ° {num_outliers} å€‹ç•°å¸¸å€¼ã€‚")
            
            df_processed = handle_outliers(df_processed, 'y', is_outlier_series_original_detection, strategy=outlier_strategy)
        else:
            st.info("æœªæª¢æ¸¬åˆ°ç•°å¸¸å€¼ã€‚")
            
    df_original_for_plot['is_outlier_original_detection'] = is_outlier_series_original_detection.reindex(df_original_for_plot.index, fill_value=False)
    df_original_for_plot.loc[df_original_for_plot['y'].isnull(), 'is_outlier_original_detection'] = False


    # --- æ•¸æ“šå¹³æ»‘ (åœ¨ç•°å¸¸å€¼è™•ç†ä¹‹å¾Œ) ---
    if apply_smoothing and smoothing_window > 1:
        df_processed['y_smoothed'] = df_processed['y'].rolling(window=smoothing_window, min_periods=1, center=True).mean()
        df_processed['y'] = df_processed['y_smoothed']
        st.info(f"æ•¸æ“šå·²æ‡‰ç”¨ç§»å‹•å¹³å‡å¹³æ»‘è™•ç†ï¼Œçª—å£å¤§å°ç‚º {smoothing_window}ã€‚")

    # æœ€çµ‚æª¢æŸ¥æ•¸æ“šæ˜¯å¦å¯ç”¨æ–¼æ¨¡å‹è¨“ç·´
    if selected_model != "Prophet" and df_processed['y'].isnull().any():
        st.error(f"éŒ¯èª¤ï¼šæ‰€é¸æ¨¡å‹ **{selected_model}** ä¸æ”¯æŒç¼ºå¤±å€¼ï¼Œä½†æ•¸æ“šä¸­ä»åŒ…å«ç¼ºå¤±å€¼ã€‚è«‹åœ¨å·¦å´å´é‚Šæ¬„é¸æ“‡å…¶ä»–ç¼ºå¤±å€¼è™•ç†ç­–ç•¥ï¼Œä¾‹å¦‚ 'ç§»é™¤ç¼ºå¤±å€¼' æˆ– 'ç·šæ€§æ’å€¼'ã€‚")
        st.stop()
    elif selected_model == "Prophet":
        df_processed.dropna(subset=['ds', 'y'], inplace=True) 

    if df_processed.empty or df_processed['y'].count() < 2: 
        st.error("ç¶“éæ•¸æ“šé è™•ç†å’Œæ™‚é–“ç¯„åœç¯©é¸å¾Œï¼Œæ²’æœ‰è¶³å¤ çš„æœ‰æ•ˆæ•¸æ“šç”¨æ–¼é æ¸¬ã€‚è«‹æª¢æŸ¥åŸå§‹æ•¸æ“šã€æ™‚é–“ç¯„åœå’Œé è™•ç†é¸é …ã€‚")
        st.stop()
        
    # --- æ•¸æ“šæ¦‚è¦½ ---
    st.subheader("ğŸ“Š æ•¸æ“šæ¦‚è¦½èˆ‡å“è³ªåˆ†æ")
    total_duration_td = df_processed['ds'].max() - df_processed['ds'].min()
    total_duration_days = total_duration_td.total_seconds() / (24*3600) 
    st.write(f"**ä½¿ç”¨æ•¸æ“šå€é–“**: å¾ **{df_processed['ds'].min().strftime('%Y-%m-%d %H:%M')}** åˆ° **{df_processed['ds'].max().strftime('%Y-%m-%d %H:%M')}**")
    st.write(f"**ç¸½æ™‚é•·**: **{total_duration_td}** (ç´„ {total_duration_days:.2f} å¤©)") 
    st.write(f"**ç¸½ç­†æ•¸**: **{len(df_processed)}** ç­†")
    try:
        inferred_freq = pd.infer_freq(df_processed['ds'])
    except ValueError:
        inferred_freq = 'ç„¡æ³•ç²¾ç¢ºæ¨æ–· (æ•¸æ“šå¯èƒ½é–“éš”ä¸ä¸€è‡´)'
    st.write(f"**æ•¸æ“šé »æ¬¡ (é è™•ç†å¾Œ)**: **{selected_freq_pandas.lower()}** (åŸå§‹æ¨æ–·: **{inferred_freq}**)") 
    
    df_for_quality_check = df_processed[['ds', 'y']].set_index('ds').rename(columns={'y': selected_param_col}).copy()
    
    quality_report = analyze_data_quality(df_for_quality_check, relevant_params=[selected_param_col])

    metrics = {} 
    if selected_param_col in quality_report:
        metrics = quality_report[selected_param_col]
        st.write(f"**åƒæ•¸: {selected_param_display_original}**")
        st.write(f"- ç¸½è¨˜éŒ„æ•¸: {metrics.get('total_records', 'N/A')}")
        st.write(f"- æœ‰æ•ˆè¨˜éŒ„æ•¸: {metrics.get('valid_count', 'N/A')}")
        st.write(f"- ç¼ºå¤±å€¼æ•¸é‡: {metrics.get('missing_count', 'N/A')} (**{metrics.get('missing_percentage', 0):.2f}%**)")
        if metrics.get('is_numeric', True):
            st.write(f"- é›¶å€¼æ•¸é‡: {metrics.get('zero_count', 'N/A')}")
            st.write(f"- è² å€¼æ•¸é‡: {metrics.get('negative_count', 'N/A')}")
            st.write(f"- æ½›åœ¨ IQR ç•°å¸¸å€¼æ•¸é‡: {metrics.get('outlier_iqr_count', 'N/A')}")

            quality_data = {
                'é¡å‹': ['æœ‰æ•ˆå€¼', 'ç¼ºå¤±å€¼', 'é›¶å€¼', 'è² å€¼', 'æ½›åœ¨ç•°å¸¸å€¼'],
                'æ•¸é‡': [
                    metrics.get('valid_count', 0),
                    metrics.get('missing_count', 0),
                    metrics.get('zero_count', 0),
                    metrics.get('negative_count', 0),
                    metrics.get('outlier_iqr_count', 0)
                ]
            }
            quality_df = pd.DataFrame(quality_data)
            quality_df = quality_df[quality_df['æ•¸é‡'] > 0] 

            if not quality_df.empty:
                fig_quality = px.pie(
                    quality_df,
                    values='æ•¸é‡',
                    names='é¡å‹',
                    title=f"'{selected_param_display_original}' æ•¸æ“šå“è³ªåˆ†ä½ˆ",
                    hole=0.3,
                    color_discrete_sequence=px.colors.qualitative.Pastel
                )
                fig_quality.update_traces(textposition='inside', textinfo='percent+label', marker=dict(line=dict(color='#000000', width=1)))
                
                fig_quality.update_layout(showlegend=True)
                
                st.plotly_chart(fig_quality, use_container_width=True)
            else:
                st.info("æ•¸æ“šå“è³ªéå¸¸é«˜ï¼Œæ²’æœ‰ç¼ºå¤±å€¼ã€é›¶å€¼ã€è² å€¼æˆ–ç•°å¸¸å€¼ã€‚")
        else:
            st.warning(f"ç„¡æ³•ç‚ºåƒæ•¸ '{selected_param_display_original}' ç”Ÿæˆæ•¸æ“šå“è³ªå ±å‘Šã€‚")


    # --- æ¨¡å‹è¨“ç·´èˆ‡é æ¸¬ ---
    forecast = pd.DataFrame()
    m = None
    
    # å„²å­˜è‡ªå‹•é¸æ“‡çš„ SARIMA/Prophet/ETS åƒæ•¸
    auto_params_display = ""
    model_summary_text = ""

    with st.spinner(f"æ­£åœ¨è¨“ç·´ {selected_model} æ¨¡å‹ä¸¦ç”Ÿæˆé æ¸¬..."):
        try:
            if selected_model == "Prophet":
                # Prophet è¦æ±‚ ds ç‚º datetimeï¼Œy ç‚ºæ•¸å€¼
                df_processed_prophet = df_processed[['ds', 'y']].copy().dropna()
                if len(df_processed_prophet) < 2:
                    st.error("Prophet æ¨¡å‹éœ€è¦è‡³å°‘å…©å€‹æœ‰æ•ˆæ•¸æ“šé»æ‰èƒ½è¨“ç·´ã€‚è«‹æ“´å¤§è¨“ç·´æ•¸æ“šç¯„åœæˆ–èª¿æ•´æ•¸æ“šé »ç‡ã€‚")
                    st.stop()

                if auto_tune_prophet and prophet_available:
                    st.info("æ­£åœ¨åŸ·è¡Œ Prophet åƒæ•¸è‡ªå‹•èª¿å„ªï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“... (åŸºæ–¼äº¤å‰é©—è­‰)")
                    
                    param_grid = {
                        'changepoint_prior_scale': np.linspace(prophet_cps_min, prophet_cps_max, prophet_cps_steps).tolist(),
                        'seasonality_prior_scale': np.linspace(prophet_sps_min, prophet_sps_max, prophet_sps_steps).tolist(),
                    }
                    grid = list(ParameterGrid(param_grid))

                    best_params = None
                    best_rmse = float('inf')
                    
                    # é—œé–‰ Prophet çš„æ—¥èªŒï¼Œé¿å…å¤§é‡è¼¸å‡º
                    prophet_logger.setLevel(logging.WARNING)

                    progress_text = "Prophet è‡ªå‹•èª¿å„ªé€²åº¦: {current_param_idx}/{total_params} çµ„åˆå·²æ¸¬è©¦ã€‚"
                    progress_bar = st.progress(0, text=progress_text.format(current_param_idx=0, total_params=len(grid)))

                    for i, params in enumerate(grid):
                        with st.spinner(f"æ­£åœ¨æ¸¬è©¦ Prophet åƒæ•¸çµ„åˆ {i+1}/{len(grid)}: {params}"):
                            m_cv = Prophet(
                                seasonality_mode=prophet_seasonality_mode,
                                changepoint_prior_scale=params['changepoint_prior_scale'],
                                seasonality_prior_scale=params['seasonality_prior_scale']
                            )
                            if prophet_holidays:
                                m_cv.add_country_holidays(country_name='TW')
                            
                            try:
                                m_cv.fit(df_processed_prophet)
                                
                                # å°‡ initial, period, horizon å¾å¤©æ•¸è½‰æ›ç‚ºé »ç‡å–®ä½
                                # æ³¨æ„ï¼šProphet çš„ initial/period/horizon åƒæ•¸å¯ä»¥ç›´æ¥æ¥å— 'Xd' æ ¼å¼
                                # é€™è£¡çš„è½‰æ›ä¸»è¦æ˜¯ç‚ºäº†æª¢æŸ¥æ•¸æ“šé‡æ˜¯å¦è¶³å¤ 
                                # é€™è£¡åªéœ€è¦ç¢ºä¿ df_processed_prophet æœ‰è¶³å¤ çš„é•·åº¦
                                if len(df_processed_prophet) < initial_period + horizon_cv:
                                    st.warning(f"æ•¸æ“šé‡ ({len(df_processed_prophet)}) ä¸è¶³ ({initial_period} å¤©åˆå§‹æ•¸æ“š + {horizon_cv} å¤©é æ¸¬å±•æœ›æœŸ)ã€‚è·³é Prophet äº¤å‰é©—è­‰ã€‚")
                                    rmse_current = float('inf')
                                else:
                                    df_cv = cross_validation(
                                        m_cv,
                                        initial=f'{initial_period} days',
                                        period=f'{period_cv} days',
                                        horizon=f'{horizon_cv} days',
                                        parallel="processes"
                                    )
                                    if df_cv.empty:
                                        rmse_current = float('inf')
                                    else:
                                        df_p = performance_metrics(df_cv)
                                        rmse_current = df_p['rmse'].mean()

                                if rmse_current < best_rmse:
                                    best_rmse = rmse_current
                                    best_params = params
                            except Exception as e:
                                # st.warning(f"Prophet åƒæ•¸çµ„åˆ {params} è¨“ç·´æˆ–äº¤å‰é©—è­‰å¤±æ•—ï¼š{e}")
                                pass # ç¹¼çºŒä¸‹ä¸€å€‹çµ„åˆï¼Œä¸ä¸­æ–· Streamlit

                        progress_bar.progress((i + 1) / len(grid), text=progress_text.format(current_param_idx=i+1, total_params=len(grid)))

                    prophet_logger.setLevel(logging.INFO) # æ¢å¾©æ—¥èªŒç´šåˆ¥

                    if best_params:
                        st.success(f"Prophet è‡ªå‹•èª¿å„ªå®Œæˆã€‚æœ€ä½³åƒæ•¸ç‚º: {best_params}")
                        prophet_changepoint_prior_scale = best_params['changepoint_prior_scale']
                        prophet_seasonality_prior_scale = best_params['seasonality_prior_scale']
                        auto_params_display = f"changepoint_prior_scale={prophet_changepoint_prior_scale:.4f}, seasonality_prior_scale={prophet_seasonality_prior_scale:.4f}"
                    else:
                        st.warning("Prophet è‡ªå‹•èª¿å„ªæœªèƒ½æ‰¾åˆ°æœ€ä½³åƒæ•¸ï¼Œå°‡ä½¿ç”¨æ‰‹å‹•è¨­å®šæˆ–é è¨­å€¼ã€‚")
                        auto_params_display = "è‡ªå‹•èª¿å„ªå¤±æ•—æˆ–æ•¸æ“šä¸è¶³ï¼Œä½¿ç”¨æ‰‹å‹•è¨­å®šå€¼ã€‚"
                else:
                    auto_params_display = "æ‰‹å‹•è¨­å®š"

                # ä½¿ç”¨æ‰‹å‹•è¨­å®šæˆ–è‡ªå‹•èª¿å„ªå¾Œçš„åƒæ•¸è¨“ç·´æœ€çµ‚æ¨¡å‹
                m = Prophet(
                    seasonality_mode=prophet_seasonality_mode,
                    changepoint_prior_scale=prophet_changepoint_prior_scale,
                    seasonality_prior_scale=prophet_seasonality_prior_scale
                )
                if prophet_holidays:
                    m.add_country_holidays(country_name='TW')
                    st.info("å·²ç‚º Prophet æ¨¡å‹æ·»åŠ å°ç£ç¯€å‡æ—¥ã€‚")

                m.fit(df_processed_prophet) # ä½¿ç”¨æ¸…ç†å¾Œçš„æ•¸æ“šé€²è¡Œè¨“ç·´
                # --- ä¿®æ­£é» 2: çµ±ä¸€ä½¿ç”¨å°å¯«é »ç‡ç¬¦è™Ÿ ---
                future = m.make_future_dataframe(periods=forecast_period_value, freq=selected_freq_pandas.lower())
                forecast = m.predict(future)

            elif selected_model == "SARIMA":
                # --- ä¿®æ­£é» 2: çµ±ä¸€ä½¿ç”¨å°å¯«é »ç‡ç¬¦è™Ÿ ---
                sarima_s_actual = SARIMA_S_OPTIONS_MAP.get(selected_prediction_freq_display, 1) 

                if auto_tune_sarima:
                    st.info("æ­£åœ¨åŸ·è¡Œ Auto-ARIMA æœç´¢æœ€ä½³åƒæ•¸ï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“...")
                    
                    model_auto_arima = pm.auto_arima(df_processed['y'].dropna(), 
                                                     seasonal=True if sarima_s_actual > 1 else False,
                                                     m=sarima_s_actual if sarima_s_actual > 1 else 1, 
                                                     D=sarima_D if not auto_tune_sarima else None, 
                                                     max_p=5, max_d=2, max_q=5,
                                                     max_P=2, max_D=1, max_Q=2,
                                                     start_p=0, start_q=0, start_P=0, start_Q=0,
                                                     trace=False, 
                                                     error_action='ignore',
                                                     suppress_warnings=True,
                                                     stepwise=True,
                                                     n_fits=50 
                                                    )
                    
                    sarima_p, sarima_d, sarima_q = model_auto_arima.order
                    sarima_P, sarima_D, sarima_Q, _ = model_auto_arima.seasonal_order
                    sarima_s = sarima_s_actual 
                    auto_params_display = f"(p={sarima_p}, d={sarima_d}, q={sarima_q})(P={sarima_P}, D={sarima_D}, Q={sarima_Q}, s={sarima_s})"
                    st.success(f"Auto-ARIMA é¸å®šçš„æœ€ä½³åƒæ•¸ç‚º: {auto_params_display}")
                else:
                    sarima_s = sarima_s_actual 
                    auto_params_display = f"(p={sarima_p}, d={sarima_d}, q={sarima_q})(P={sarima_P}, D={sarima_D}, Q={sarima_Q}, s={sarima_s})"

                min_sarima_data_points = max(2 * sarima_s, 2 * (sarima_p + sarima_P)) if sarima_s > 1 else (sarima_p + sarima_d + sarima_q + 10)
                if len(df_processed) < min_sarima_data_points:
                    st.error(f"æ•¸æ“šé» ({len(df_processed)}) ä¸è¶³ï¼Œç„¡æ³•è¨“ç·´ SARIMA æ¨¡å‹ã€‚è‡³å°‘éœ€è¦ç´„ {min_sarima_data_points} é»ã€‚è«‹èª¿æ•´æ•¸æ“šç¯„åœæˆ–é æ¸¬é »æ¬¡ã€‚")
                    st.stop()

                model_sarima = SARIMAX(df_processed['y'],
                                       order=(sarima_p, sarima_d, sarima_q),
                                       seasonal_order=(sarima_P, sarima_D, sarima_Q, sarima_s) if sarima_s > 1 else (0,0,0,0),
                                       enforce_stationarity=False,
                                       enforce_invertibility=False)
                results_sarima = model_sarima.fit(disp=False)
                model_summary_text = results_sarima.summary().as_text()
                
                n_predict = len(df_processed) + forecast_period_value
                sarima_forecast = results_sarima.get_prediction(start=0, end=n_predict - 1)
                
                forecast_mean = sarima_forecast.predicted_mean
                conf_int = sarima_forecast.conf_int(alpha=0.05)

                forecast = pd.DataFrame({
                    'ds': pd.date_range(start=df_processed['ds'].min(), periods=n_predict, freq=selected_freq_pandas.lower()), 
                    'yhat': forecast_mean,
                    'yhat_lower': conf_int.iloc[:, 0],
                    'yhat_upper': conf_int.iloc[:, 1]
                })
                forecast = forecast[forecast['ds'].isin(df_processed['ds']) | (forecast['ds'] > df_processed['ds'].max())].copy()


            elif selected_model == "ETS":
                ets_seasonal_periods_actual = SARIMA_S_OPTIONS_MAP.get(selected_prediction_freq_display, 1)

                if auto_tune_ets and statsmodels_available:
                    st.info("æ­£åœ¨åŸ·è¡Œ ETS åƒæ•¸è‡ªå‹•èª¿å„ªï¼Œé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“...")
                    
                    param_grid = {
                        'error': ets_error_options_auto,
                        'trend': ets_trend_options_auto,
                        'seasonal': ets_seasonal_options_auto,
                    }
                    grid = list(ParameterGrid(param_grid))

                    best_params = None
                    best_rmse = float('inf')
                    
                    progress_text = "ETS è‡ªå‹•èª¿å„ªé€²åº¦: {current_param_idx}/{total_params} çµ„åˆå·²æ¸¬è©¦ã€‚"
                    progress_bar = st.progress(0, text=progress_text.format(current_param_idx=0, total_params=len(grid)))

                    for i, params in enumerate(grid):
                        with st.spinner(f"æ­£åœ¨æ¸¬è©¦ ETS åƒæ•¸çµ„åˆ {i+1}/{len(grid)}: {params}"):
                            current_ets_seasonal_periods = ets_seasonal_periods_actual if params['seasonal'] else 1

                            try:
                                min_ets_data_points = current_ets_seasonal_periods * 2 if params['seasonal'] else 10
                                if len(df_processed) < min_ets_data_points:
                                    rmse_current = float('inf')
                                else:
                                    model_ets_cv = ExponentialSmoothing(
                                        df_processed['y'],
                                        seasonal_periods=current_ets_seasonal_periods if params['seasonal'] else None,
                                        trend=params['trend'],
                                        seasonal=params['seasonal'],
                                        initialization_method="estimated"
                                    ).fit(disp=False)

                                    y_pred_cv = model_ets_cv.fittedvalues
                                    valid_indices_cv = ~np.isnan(df_processed['y']) & ~np.isnan(y_pred_cv)
                                    if valid_indices_cv.any():
                                        rmse_current = np.sqrt(mean_squared_error(df_processed['y'][valid_indices_cv], y_pred_cv[valid_indices_cv]))
                                    else:
                                        rmse_current = float('inf')

                                if rmse_current < best_rmse:
                                    best_rmse = rmse_current
                                    best_params = params
                                    best_params['seasonal_periods'] = current_ets_seasonal_periods
                            except Exception as e:
                                pass 

                        progress_bar.progress((i + 1) / len(grid), text=progress_text.format(current_param_idx=i+1, total_params=len(grid)))

                    if best_params:
                        st.success(f"ETS è‡ªå‹•èª¿å„ªå®Œæˆã€‚æœ€ä½³åƒæ•¸ç‚º: {best_params}")
                        ets_error = best_params['error']
                        ets_trend = best_params['trend']
                        ets_seasonal = best_params['seasonal']
                        ets_seasonal_periods = best_params['seasonal_periods']
                        auto_params_display = f"error='{ets_error}', trend='{ets_trend}', seasonal='{ets_seasonal}', seasonal_periods={ets_seasonal_periods}"
                    else:
                        st.warning("ETS è‡ªå‹•èª¿å„ªæœªèƒ½æ‰¾åˆ°æœ€ä½³åƒæ•¸ï¼Œå°‡ä½¿ç”¨æ‰‹å‹•è¨­å®šæˆ–é è¨­å€¼ã€‚")
                        auto_params_display = "è‡ªå‹•èª¿å„ªå¤±æ•—æˆ–æ•¸æ“šä¸è¶³ï¼Œä½¿ç”¨æ‰‹å‹•è¨­å®šå€¼ã€‚"
                else:
                    ets_seasonal_periods = ets_seasonal_periods_actual
                    auto_params_display = "æ‰‹å‹•è¨­å®š"

                min_ets_data_points = ets_seasonal_periods * 2 if ets_seasonal else 10
                if len(df_processed) < min_ets_data_points:
                    st.error(f"æ•¸æ“šé» ({len(df_processed)}) ä¸è¶³ï¼Œç„¡æ³•è¨“ç·´ ETS æ¨¡å‹ã€‚è‡³å°‘éœ€è¦ç´„ {min_ets_data_points} é»ã€‚è«‹èª¿æ•´æ•¸æ“šç¯„åœæˆ–é æ¸¬é »æ¬¡ã€‚")
                    st.stop()

                model_ets = ExponentialSmoothing(
                    df_processed['y'],
                    seasonal_periods=ets_seasonal_periods if ets_seasonal else None,
                    trend=ets_trend,
                    seasonal=ets_seasonal,
                    initialization_method="estimated"
                ).fit()
                
                model_summary_text = model_ets.summary().as_text()

                ets_forecast = model_ets.predict(start=0, end=len(df_processed) + forecast_period_value -1)

                forecast = pd.DataFrame({
                    'ds': pd.date_range(start=df_processed['ds'].min(), periods=len(df_processed) + forecast_period_value, freq=selected_freq_pandas.lower()), 
                    'yhat': ets_forecast
                })
                forecast['yhat_lower'] = np.nan
                forecast['yhat_upper'] = np.nan
                forecast = forecast[forecast['ds'].isin(df_processed['ds']) | (forecast['ds'] > df_processed['ds'].max())].copy()

        except Exception as e:
            st.error(f"æ¨¡å‹è¨“ç·´æˆ–é æ¸¬å¤±æ•—ï¼š{e}ã€‚è«‹æª¢æŸ¥æ•¸æ“šæˆ–èª¿æ•´æ¨¡å‹åƒæ•¸ã€‚")
            st.stop()

    st.success(f"{selected_model} æ¨¡å‹é æ¸¬å®Œæˆï¼")

    # --- æ€§èƒ½æŒ‡æ¨™è¨ˆç®—èˆ‡é¡¯ç¤º (é‡å°ä¸»é æ¸¬) ---
    st.subheader("ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ¨™ (è¨“ç·´æ•¸æ“š)")
    if auto_params_display:
        st.info(f"**{selected_model} ä½¿ç”¨åƒæ•¸**: {auto_params_display}")

    actual_vs_predicted = pd.merge(df_processed[['ds', 'y']], forecast[['ds', 'yhat']], on='ds', how='inner')
    
    performance_metrics_report = {} 

    if not actual_vs_predicted.empty:
        y_true = actual_vs_predicted['y']
        y_pred = actual_vs_predicted['yhat']

        valid_indices = ~np.isnan(y_true) & ~np.isnan(y_pred)
        y_true_clean = y_true[valid_indices]
        y_pred_clean = y_pred[valid_indices]

        if len(y_true_clean) > 0:
            rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))
            mae = mean_absolute_error(y_true_clean, y_pred_clean)
            
            correlation = np.nan
            if len(y_true_clean) > 1 and len(y_pred_clean) > 1 and y_true_clean.std() > 0 and y_pred_clean.std() > 0:
                try:
                    correlation, _ = pearsonr(y_true_clean, y_pred_clean)
                except Exception as e:
                    st.warning(f"è¨ˆç®—ç›¸é—œä¿‚æ•¸å¤±æ•—: {e}")
            else:
                st.warning("æ•¸æ“šé»ä¸è¶³æˆ–æ•¸æ“šç„¡è®ŠåŒ–ï¼Œç„¡æ³•è¨ˆç®—ç›¸é—œä¿‚æ•¸ã€‚")

            mape = np.nan
            if (y_true_clean != 0).any():
                non_zero_mape_indices = y_true_clean != 0
                if non_zero_mape_indices.any():
                    mape = np.mean(np.abs((y_true_clean[non_zero_mape_indices] - y_pred_clean[non_zero_mape_indices]) / y_true_clean[non_zero_mape_indices])) * 100
                else:
                    st.warning("è­¦å‘Š: ç„¡æ³•è¨ˆç®— MAPEï¼Œå› ç‚ºè¨“ç·´æ•¸æ“šä¸­çš„å¯¦éš›å€¼å…¨éƒ¨ç‚ºé›¶ã€‚")
            else:
                st.warning("è­¦å‘Š: ç„¡æ³•è¨ˆç®— MAPEï¼Œå› ç‚ºè¨“ç·´æ•¸æ“šä¸­çš„å¯¦éš›å€¼å…¨éƒ¨ç‚ºé›¶ã€‚")

            st.markdown(f"**å‡æ–¹æ ¹èª¤å·® (RMSE):** `{rmse:.4f}`")
            st.markdown(f"**å¹³å‡çµ•å°èª¤å·® (MAE):** `{mae:.4f}`")
            if not np.isnan(mape):
                st.markdown(f"**å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·® (MAPE):** `{mape:.2f}%`")
            else:
                st.markdown("**å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·® (MAPE):** `N/A` (æ•¸æ“šå•é¡Œç„¡æ³•è¨ˆç®—)")
            
            if not np.isnan(correlation):
                st.markdown(f"**ç›¸é—œä¿‚æ•¸ (Correlation Coefficient):** `{correlation:.4f}`")
            else:
                st.markdown("**ç›¸é—œä¿‚æ•¸ (Correlation Coefficient):** `N/A` (æ•¸æ“šé»ä¸è¶³æˆ–è¨ˆç®—å¤±æ•—)")

            performance_metrics_report['RMSE'] = f"{rmse:.4f}"
            performance_metrics_report['MAE'] = f"{mae:.4f}"
            performance_metrics_report['MAPE'] = f"{mape:.2f}%" if not np.isnan(mape) else "N/A"
            performance_metrics_report['Correlation Coefficient'] = f"{correlation:.4f}" if not np.isnan(correlation) else "N/A"

            st.markdown("---")
            st.markdown("é€™äº›æŒ‡æ¨™è¡¡é‡æ¨¡å‹åœ¨è¨“ç·´æ•¸æ“šä¸Šçš„æ“¬åˆæº–ç¢ºæ€§ï¼š")
            st.markdown("- **RMSE (Root Mean Squared Error)**ï¼šé æ¸¬å€¼èˆ‡å¯¦éš›å€¼åå·®çš„å¹³æ–¹å¹³å‡æ•¸çš„å¹³æ–¹æ ¹ã€‚å€¼è¶Šå°è¡¨ç¤ºæ¨¡å‹è¶Šæº–ç¢ºã€‚å°å¤§èª¤å·®çš„æ‡²ç½°æ›´å¤§ã€‚")
            st.markdown("- **MAE (Mean Absolute Error)**ï¼šé æ¸¬å€¼èˆ‡å¯¦éš›å€¼åå·®çš„çµ•å°å€¼å¹³å‡æ•¸ã€‚å€¼è¶Šå°è¡¨ç¤ºæ¨¡å‹è¶Šæº–ç¢ºã€‚")
            st.markdown("- **MAPE (Mean Absolute Percentage Error)**ï¼šé æ¸¬èª¤å·®çš„ç™¾åˆ†æ¯”ã€‚å°æ–¼ç†è§£èª¤å·®ç›¸å°æ–¼å¯¦éš›å€¼çš„æ¯”ä¾‹å¾ˆæœ‰ç”¨ã€‚å€¼è¶Šå°è¶Šå¥½ã€‚")
            st.markdown("- **ç›¸é—œä¿‚æ•¸ (Correlation Coefficient)**ï¼šè¡¡é‡å…©å€‹è®Šé‡ï¼ˆå¯¦éš›å€¼å’Œé æ¸¬å€¼ï¼‰ä¹‹é–“ç·šæ€§é—œä¿‚çš„å¼·åº¦å’Œæ–¹å‘ã€‚å€¼è¶Šæ¥è¿‘ `1` è¡¨ç¤ºæ­£å‘ç·šæ€§é—œä¿‚è¶Šå¼·ï¼›è¶Šæ¥è¿‘ `-1` è¡¨ç¤ºè² å‘ç·šæ€§é—œä¿‚è¶Šå¼·ï¼›æ¥è¿‘ `0` è¡¨ç¤ºç·šæ€§é—œä¿‚å¾ˆå¼±ã€‚ç†æƒ³æƒ…æ³ä¸‹ï¼Œæ­¤å€¼æ‡‰æ¥è¿‘ `1`ã€‚")
        else:
            st.warning("æ²’æœ‰è¶³å¤ çš„é‡ç–Šæ•¸æ“šé»ä¾†è¨ˆç®—æ€§èƒ½æŒ‡æ¨™ã€‚")
    else:
        st.warning("ç„¡æ³•å°‡å¯¦éš›å€¼èˆ‡é æ¸¬å€¼å°é½Šä»¥è¨ˆç®—æ€§èƒ½æŒ‡æ¨™ã€‚è«‹æª¢æŸ¥æ•¸æ“šå’Œé æ¸¬æ™‚é–“ç¯„åœã€‚")


    ### ğŸ“ˆ é æ¸¬çµæœè¦–è¦ºåŒ–

    st.subheader("ğŸ“ˆ é æ¸¬çµæœ")
    if not forecast.empty:
        # åˆä½µåŸå§‹æ•¸æ“šå’Œè™•ç†å¾Œçš„æ•¸æ“šï¼Œç”¨æ–¼å¯è¦–åŒ–å°æ¯”
        plot_df = pd.merge(df_original_for_plot[['ds', 'y', 'is_outlier_original_detection']],
                            df_processed[['ds', 'y']], 
                            on='ds',
                            how='inner', 
                            suffixes=('_original', '_processed'))
        
        # åˆä½µé æ¸¬çµæœ
        plot_df = pd.merge(plot_df, forecast, on='ds', how='left')


        fig = go.Figure()

        # æ·»åŠ åŸå§‹å¯¦éš›æ•¸æ“š (å¯èƒ½å«æœ‰æ–·è£‚é»)
        fig.add_trace(go.Scatter(
            x=plot_df['ds'],
            y=plot_df['y_original'],
            mode='lines',
            name='åŸå§‹æ•¸æ“š',
            line=dict(color='blue', dash='dot')
        ))
        
        # æ·»åŠ ç¶“éé è™•ç†ï¼ˆåŒ…æ‹¬ç•°å¸¸å€¼è™•ç†å’Œå¹³æ»‘ï¼‰çš„æ•¸æ“š
        fig.add_trace(go.Scatter(
            x=plot_df['ds'],
            y=plot_df['y_processed'],
            mode='lines',
            name='è™•ç†å¾Œæ•¸æ“š',
            line=dict(color='darkgreen', width=2)
        ))


        # --- æ¨™è¨˜åŸå§‹æ•¸æ“šä¸­çš„ç•°å¸¸å€¼ ---
        outlier_df_to_show = plot_df[plot_df['is_outlier_original_detection'] & plot_df['y_original'].notna()].copy()
        if not outlier_df_to_show.empty:
            fig.add_trace(go.Scatter(
                x=outlier_df_to_show['ds'],
                y=outlier_df_to_show['y_original'],
                mode='markers',
                name='æª¢æ¸¬åˆ°çš„åŸå§‹ç•°å¸¸å€¼',
                marker=dict(color='red', size=8, symbol='x', line=dict(width=1, color='DarkRed'))
            ))
        else:
            st.info("æœªæª¢æ¸¬åˆ°æœ‰æ•ˆç•°å¸¸å€¼é»ä¾†é¡¯ç¤ºã€‚")
        # --- æ¨™è¨˜ç•°å¸¸å€¼çµæŸ ---

        # é æ¸¬ç·š
        fig.add_trace(go.Scatter(
            x=forecast['ds'],
            y=forecast['yhat'],
            mode='lines',
            name='é æ¸¬å€¼',
            line=dict(color='red', dash='dash', width=2)
        ))

        # é æ¸¬å€é–“
        if 'yhat_lower' in forecast.columns and not forecast['yhat_lower'].isnull().all():
            fig.add_trace(go.Scatter(
                x=forecast['ds'],
                y=forecast['yhat_lower'],
                mode='lines',
                name='é æ¸¬ä¸‹é™',
                line=dict(color='lightcoral', width=0),
                showlegend=False
            ))
            fig.add_trace(go.Scatter(
                x=forecast['ds'],
                y=forecast['yhat_upper'],
                mode='lines',
                name='é æ¸¬ä¸Šé™',
                fill='tonexty',
                fillcolor='rgba(255,0,0,0.1)',
                line=dict(color='lightcoral', width=0)
            ))
        
        # å¸ƒæ—å¸¶
        if apply_bollinger_bands:
            if len(df_processed) >= bb_window:
                df_processed_bb = calculate_bollinger_bands(df_processed.copy(), window=bb_window, num_std_dev=bb_num_std)
                if df_processed_bb is not None:
                    fig.add_trace(go.Scatter(
                        x=df_processed_bb['ds'], y=df_processed_bb['MA'], mode='lines', name='å¸ƒæ—å¸¶ä¸­è»Œ (MA)',
                        line=dict(color='purple', dash='dot')
                    ))
                    fig.add_trace(go.Scatter(
                        x=df_processed_bb['ds'], y=df_processed_bb['Upper'], mode='lines', name='å¸ƒæ—ä¸Šè»Œ',
                        line=dict(color='green', dash='dot')
                    ))
                    fig.add_trace(go.Scatter(
                        x=df_processed_bb['ds'], y=df_processed_bb['Lower'], mode='lines', name='å¸ƒæ—ä¸‹è»Œ',
                        line=dict(color='orange', dash='dot')
                    ))
            else:
                st.warning(f"æ•¸æ“šé» ({len(df_processed)}) å°‘æ–¼å¸ƒæ—å¸¶çª—å£ {bb_window}ï¼Œç„¡æ³•é¡¯ç¤ºå¸ƒæ—å¸¶ã€‚")


        forecast_unit_display = selected_prediction_freq_display.split(' ')[0]
        
        fig.update_layout(
            title=f"{selected_station_name} - {selected_param_display_original} æœªä¾† {forecast_period_value} {forecast_unit_display} é æ¸¬ ({selected_model})",
            xaxis_title="æ™‚é–“",
            yaxis_title=f"{selected_param_display_original} {param_unit}",
            hovermode="x unified",
            height=600,
            xaxis=dict(rangeslider_visible=True) 
        )

        st.plotly_chart(fig, use_container_width=True)

        ### ğŸ’¾ ä¸‹è¼‰é æ¸¬çµæœèˆ‡å ±å‘Š

        st.markdown("æ‚¨å¯ä»¥ä¸‹è¼‰åŒ…å«é æ¸¬å€¼å’Œä¸ç¢ºå®šæ€§å€é–“çš„ CSV æ–‡ä»¶ï¼Œæˆ–è€…ä¸‹è¼‰**äº’å‹•å¼ HTML åœ–è¡¨**ï¼Œä»¥åŠ**é æ¸¬å ±å‘Š**ã€‚")

        # --- ä¸‹è¼‰äº’å‹•å¼ HTML åœ–è¡¨ ---
        if not forecast.empty and fig:
            html_export_string = pio.to_html(fig, full_html=True, include_plotlyjs='cdn')

            st.download_button(
                label="ä¸‹è¼‰äº’å‹•å¼ HTML åœ–è¡¨",
                data=html_export_string.encode('utf-8'),
                file_name=f"{selected_station_name}_{selected_param_col}_{selected_model}_forecast_chart.html",
                mime="text/html",
                help="ä¸‹è¼‰å¯ç¨ç«‹æ‰“é–‹ä¸¦äº’å‹•çš„åœ–è¡¨ HTML æ–‡ä»¶"
            )


        download_df = forecast.copy()
        download_df.rename(columns={'ds': 'æ™‚é–“', 'yhat': f'é æ¸¬å€¼_{selected_param_display_original}',
                                     'yhat_lower': f'é æ¸¬ä¸‹é™_{selected_param_display_original}',
                                     'yhat_upper': f'é æ¸¬ä¸Šé™_{selected_param_display_original}'}, inplace=True)
        download_df['æ™‚é–“'] = download_df['æ™‚é–“'].dt.strftime('%Y-%m-%d %H:%M:%S')

        csv_data = download_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ä¸‹è¼‰é æ¸¬ CSV æ–‡ä»¶",
            data=csv_data,
            file_name=f"{selected_station_name}_{selected_param_col}_{selected_model}_forecast.csv",
            mime="text/csv",
        )

        # --- ç”Ÿæˆä¸¦ä¸‹è¼‰é æ¸¬å ±å‘Š ---
        report_content = f"""
# æ™‚é–“åºåˆ—é æ¸¬å ±å‘Š - {selected_station_name} - {selected_param_display_original}

## 1. é æ¸¬æ¦‚è¦½
- **æ¸¬ç«™**: {selected_station_name}
- **é æ¸¬åƒæ•¸**: {selected_param_display_original} ({param_unit})
- **é æ¸¬æ¨¡å‹**: {selected_model}
- **é æ¸¬æœªä¾†æ™‚é•·**: {forecast_period_value} {forecast_unit_display}
- **é æ¸¬é »æ¬¡**: {selected_freq_pandas.lower()}

## 2. æ•¸æ“šæ¦‚è¦½èˆ‡å“è³ªåˆ†æ
- **ä½¿ç”¨æ•¸æ“šå€é–“**: å¾ {df_processed['ds'].min().strftime('%Y-%m-%d %H:%M')} åˆ° {df_processed['ds'].max().strftime('%Y-%m-%d %H:%M')}
- **ç¸½æ™‚é•·**: {total_duration_td} (ç´„ {total_duration_days:.2f} å¤©)
- **ç¸½ç­†æ•¸**: {len(df_processed)} ç­†
- **æ•¸æ“šé »æ¬¡ (é è™•ç†å¾Œ)**: {selected_freq_pandas.lower()}

### æ•¸æ“šå“è³ªå ±å‘Š
- ç¸½è¨˜éŒ„æ•¸: {metrics.get('total_records', 'N/A')}
- æœ‰æ•ˆè¨˜éŒ„æ•¸: {metrics.get('valid_count', 'N/A')}
- ç¼ºå¤±å€¼æ•¸é‡: {metrics.get('missing_count', 'N/A')} ({metrics.get('missing_percentage', 0):.2f}%)
- é›¶å€¼æ•¸é‡: {metrics.get('zero_count', 'N/A')}
- è² å€¼æ•¸é‡: {metrics.get('negative_count', 'N/A')}
- æ½›åœ¨ IQR ç•°å¸¸å€¼æ•¸é‡: {metrics.get('outlier_iqr_count', 'N/A')}

## 3. æ•¸æ“šé è™•ç†è¨­å®š
- **ç¼ºå¤±å€¼è™•ç†ç­–ç•¥**: {missing_value_strategy}
- **ç•°å¸¸å€¼æª¢æ¸¬æ–¹æ³•**: {outlier_method}
- **ç•°å¸¸å€¼è™•ç†ç­–ç•¥**: {outlier_strategy}
"""
        if outlier_method != 'ç„¡':
            report_content += f"  - æª¢æ¸¬åˆ°çš„ç•°å¸¸å€¼æ•¸é‡: {num_outliers}\n"
        
        report_content += f"""- **æ•¸æ“šå¹³æ»‘è™•ç†**: {'æ˜¯' if apply_smoothing and smoothing_window > 1 else 'å¦'}"""
        if apply_smoothing and smoothing_window > 1:
            report_content += f""" (ç§»å‹•å¹³å‡è¦–çª—: {smoothing_window})
"""
        else:
            report_content += "\n"

        report_content += f"""
## 4. æ¨¡å‹åƒæ•¸èˆ‡è¨“ç·´
- **æ¨¡å‹é¡å‹**: {selected_model}
- **ä½¿ç”¨åƒæ•¸**: {auto_params_display}
"""
        if model_summary_text:
            report_content += f"""
### æ¨¡å‹è¨“ç·´æ‘˜è¦
{model_summary_text}


"""

        report_content += f"""
## 5. æ¨¡å‹æ€§èƒ½æŒ‡æ¨™ (è¨“ç·´æ•¸æ“š)
- **å‡æ–¹æ ¹èª¤å·® (RMSE)**: {performance_metrics_report.get('RMSE', 'N/A')}
- **å¹³å‡çµ•å°èª¤å·® (MAE)**: {performance_metrics_report.get('MAE', 'N/A')}
- **å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·® (MAPE)**: {performance_metrics_report.get('MAPE', 'N/A')}
- **ç›¸é—œä¿‚æ•¸ (Correlation Coefficient)**: {performance_metrics_report.get('Correlation Coefficient', 'N/A')}

---
å ±å‘Šç”Ÿæˆæ™‚é–“: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

        st.download_button(
            label="ä¸‹è¼‰é æ¸¬å ±å‘Š (TXT)",
            data=report_content.encode('utf-8'),
            file_name=f"{selected_station_name}_{selected_param_col}_{selected_model}_forecast_report.txt",
            mime="text/plain",
            help="ä¸‹è¼‰åŒ…å«é æ¸¬è¨­å®šã€æ•¸æ“šå“è³ªã€æ¨¡å‹åƒæ•¸å’Œæ€§èƒ½æŒ‡æ¨™çš„æ–‡æœ¬å ±å‘Š"
        )


    else:
        st.warning("é æ¸¬çµæœç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œå¯è¦–åŒ–æˆ–ä¸‹è¼‰ã€‚")
