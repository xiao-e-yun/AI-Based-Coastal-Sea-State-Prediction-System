import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io
import zipfile
from scipy import signal
from scipy.stats import mstats, linregress

from utils.helpers import get_station_name_from_id, initialize_session_state

# ç‚ºäº†è®“æ­¤è…³æœ¬èƒ½ç¨ç«‹é‹è¡Œï¼Œæˆ‘å€‘æ¨¡æ“¬è¼”åŠ©å‡½å¼çš„åŠŸèƒ½
# åœ¨æ‚¨çš„å°ˆæ¡ˆä¸­ï¼Œè«‹ç¢ºä¿ from utils.helpers import ... æ˜¯æœ‰æ•ˆçš„
def load_year_data(base_path, station, year):
    """æ¨¡æ“¬å¾æª”æ¡ˆè¼‰å…¥è³‡æ–™çš„å‡½å¼ã€‚"""
    # ç‚ºäº†æ¸¬è©¦ç¯©é¸åŠŸèƒ½ï¼Œè®“ StationC åœ¨ 2021 å¹´æ²’æœ‰è³‡æ–™
    if station == 'StationC' and year == '2021':
        return None
    
    np.random.seed(hash(f"{station}{year}") % (2**32 - 1)) # ç¢ºä¿æ¯æ¬¡ç”Ÿæˆçš„å‡è³‡æ–™éƒ½ä¸€æ¨£
    date_rng = pd.date_range(start=f'{year}-01-01', end=f'{year}-12-31', freq='H')
    df = pd.DataFrame(date_rng, columns=['time'])
    df['Wave_Height_Significant'] = np.random.normal(1.5, 0.5, size=len(date_rng))
    df['Wave_Mean_Period'] = np.random.normal(8, 1, size=len(date_rng))
    df['Wave_Peak_Period'] = np.random.normal(12, 2, size=len(date_rng))
    df['Wind_Speed'] = np.random.normal(10, 3, size=len(date_rng))
    df['Wind_Gust_Speed'] = np.random.normal(15, 4, size=len(date_rng))
    df['Air_Temperature'] = np.random.normal(25, 5, size=len(date_rng))
    df['Sea_Temperature'] = np.random.normal(26, 3, size=len(date_rng))
    df['Air_Pressure'] = np.random.normal(1010, 5, size=len(date_rng))
    df['Wind_Direction'] = np.random.randint(0, 360, size=len(date_rng))
    df['Wave_Main_Direction'] = np.random.randint(0, 360, size=len(date_rng))
    # éš¨æ©Ÿæ’å…¥ä¸€äº›ç¼ºå¤±å€¼èˆ‡ç•°å¸¸å€¼
    df.loc[df.sample(frac=0.1).index, 'Wave_Height_Significant'] = np.nan
    df.loc[df.sample(frac=0.02).index, 'Wind_Speed'] = 99.9 # ç•°å¸¸å€¼
    df.loc[df.sample(frac=0.01).index, 'Wave_Mean_Period'] = -10 # ç•°å¸¸å€¼
    return df

def convert_df_to_csv(df):
    """å°‡ DataFrame è½‰æ›ç‚º CSV æ ¼å¼çš„ bytesã€‚"""
    return df.to_csv(index=False).encode('utf-8')


# --- é é¢åŸºç¤è¨­å®š ---
st.set_page_config(layout="wide")
st.title('ğŸ“ˆ æ¸¬ç«™è³‡æ–™åˆ†æå¹³å°')
st.write("æä¾›æ¸¬ç«™ç›¸é—œæ€§åˆ†æèˆ‡æ•¸æ“šå“è³ªæª¢è¦–åŠŸèƒ½ã€‚")
initialize_session_state()

# --- å¸¸æ•¸èˆ‡å­—å…¸å®šç¾© ---
PARAM_DISPLAY_NAMES = {
    "Wave_Height_Significant": "ç¤ºæ€§æ³¢é«˜", "Wave_Mean_Period": "å¹³å‡æ³¢é€±æœŸ",
    "Wave_Peak_Period": "æ³¢æµªå°–å³°é€±æœŸ", "Wind_Speed": "é¢¨é€Ÿ",
    "Wind_Gust_Speed": "é™£é¢¨é¢¨é€Ÿ", "Air_Temperature": "æ°£æº«",
    "Sea_Temperature": "æµ·é¢æº«åº¦", "Air_Pressure": "æ°£å£“",
    "Wind_Direction": "é¢¨å‘", "Wave_Main_Direction": "æ³¢å‘"
}
PARAM_UNITS = {
    "Wave_Height_Significant": " (m)", "Wave_Mean_Period": " (sec)",
    "Wave_Peak_Period": " (sec)", "Wind_Speed": " (m/s)",
    "Wind_Gust_Speed": " (m/s)", "Air_Temperature": " (Â°C)",
    "Sea_Temperature": " (Â°C)", "Air_Pressure": " (hPa)",
    "Wind_Direction": " (Â°)", "Wave_Main_Direction": " (Â°)"
}

# --- å¿«å–è¨ˆç®—å‡½å¼ (æ ¸å¿ƒå„ªåŒ–) ---
@st.cache_data
def calculate_data_quality(df):
    """
    è¨ˆç®—å‚³å…¥çš„ DataFrame çš„æ•¸æ“šå“è³ªï¼ŒåŒ…å«ç•°å¸¸å€¼æª¢æ¸¬ (IQR)ã€‚
    """
    if df is None or df.empty:
        return None

    quality_stats = []
    params_to_check = [col for col in df.columns if col != 'time']
    total_records = len(df)

    for param in params_to_check:
        valid_series = df[param].dropna()
        valid_count = len(valid_series)
        missing_count = total_records - valid_count
        completeness = (valid_count / total_records * 100) if total_records > 0 else 0
        
        outlier_count = 0
        if valid_count > 1 and pd.api.types.is_numeric_dtype(valid_series):
            Q1 = valid_series.quantile(0.25)
            Q3 = valid_series.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = valid_series[(valid_series < lower_bound) | (valid_series > upper_bound)]
            outlier_count = len(outliers)

        quality_stats.append({
            "åƒæ•¸": PARAM_DISPLAY_NAMES.get(param, param),
            "æœ‰æ•ˆå€¼": valid_count,
            "ç¼ºå¤±å€¼": missing_count,
            "ç•°å¸¸å€¼": outlier_count,
            "å®Œæ•´åº¦ (%)": completeness
        })
    
    return pd.DataFrame(quality_stats)

@st.cache_data
def calculate_single_year_correlation(_base_path, station1, station2, year, param_col, analysis_type):
    """
    è¼‰å…¥ä¸¦è¨ˆç®—å–®ä¸€å¹´ä»½çš„ç›¸é—œæ€§è³‡æ–™ï¼Œä¸¦åŒ…å«å…©æ¸¬ç«™çš„æ•¸æ“šå“è³ªå ±å‘Šã€‚
    """
    df1_raw = load_year_data(_base_path, station1, year)
    df2_raw = load_year_data(_base_path, station2, year)
    
    quality1_df = calculate_data_quality(df1_raw)
    quality2_df = calculate_data_quality(df2_raw)

    results = {"df1_raw": df1_raw, "df2_raw": df2_raw, "quality1": quality1_df, "quality2": quality2_df}

    if df1_raw is None or df2_raw is None or df1_raw.empty or df2_raw.empty:
        return {"error": f"éŒ¯èª¤ï¼šæœªèƒ½è¼‰å…¥ {year} å¹´ {station1} æˆ– {station2} çš„è³‡æ–™ï¼Œæˆ–è³‡æ–™ç‚ºç©ºã€‚", **results}

    if analysis_type == 'linear':
        if param_col not in df1_raw.columns or param_col not in df2_raw.columns:
            return {"error": f"éŒ¯èª¤ï¼šè³‡æ–™ä¸­ç¼ºå°‘ '{PARAM_DISPLAY_NAMES.get(param_col, param_col)}' æ¬„ä½ã€‚", **results}
        
        merged = pd.merge(df1_raw[['time', param_col]], df2_raw[['time', param_col]], on='time', how='inner', suffixes=(f'_{station1}', f'_{station2}')).dropna()
        if len(merged) < 2:
            return {"error": "å…±åŒæ™‚é–“å…§ç„¡è¶³å¤ æ•¸æ“šé€²è¡Œç›¸é—œæ€§åˆ†æã€‚", **results}
            
        slope, intercept, r_value, _, _ = linregress(merged.iloc[:, 1], merged.iloc[:, 2])
        results.update({
            "type": "linear", "merged": merged, "corr": r_value, "slope": slope, 
            "intercept": intercept, "r_squared": r_value**2, "x_col": merged.columns[1], "y_col": merged.columns[2]
        })

    elif analysis_type == 'circular':
        mag_col = 'Wind_Speed' if 'Wind' in param_col else 'Wave_Height_Significant'
        if not all(c in df1_raw.columns and c in df2_raw.columns for c in [param_col, mag_col]):
            return {"error": f"éŒ¯èª¤ï¼šè³‡æ–™ä¸­ç¼ºå°‘ '{PARAM_DISPLAY_NAMES.get(param_col, param_col)}' æˆ–å°æ‡‰é‡å€¼æ¬„ä½ã€‚", **results}

        for df, s_name in [(df1_raw, station1), (df2_raw, station2)]:
            df_dropna = df.dropna(subset=[param_col, mag_col])
            if not df_dropna.empty:
                rad = np.radians(df_dropna[param_col])
                mag = df_dropna[mag_col]
                df.loc[df_dropna.index, f'u_{s_name}'] = -mag * np.sin(rad)
                df.loc[df_dropna.index, f'v_{s_name}'] = -mag * np.cos(rad)

        merged_uv = pd.merge(df1_raw[['time', f'u_{station1}', f'v_{station1}']], df2_raw[['time', f'u_{station2}', f'v_{station2}']], on='time', how='inner').dropna()

        if len(merged_uv) < 2:
            return {"error": "å…±åŒæ™‚é–“å…§ç„¡è¶³å¤ U/Våˆ†é‡æ•¸æ“šé€²è¡Œåˆ†æã€‚", **results}

        corr_u = merged_uv[f'u_{station1}'].corr(merged_uv[f'u_{station2}'])
        corr_v = merged_uv[f'v_{station1}'].corr(merged_uv[f'v_{station2}'])
        results.update({
            "type": "circular", "merged": merged_uv, "corr_u": corr_u, "corr_v": corr_v, "mag_col": mag_col
        })
        
    return results

@st.cache_data
def calculate_yearly_trend(_base_path, s1, s2, param_col, start_y, end_y):
    """
    è¨ˆç®—é€å¹´ç›¸é—œæ€§è¶¨å‹¢ï¼Œä¸¦å›å‚³ç”¨æ–¼è¨ˆç®—çš„è³‡æ–™é»æ•¸é‡ã€‚
    """
    results_data = []
    years_to_analyze = range(int(start_y), int(end_y) + 1)
    bar = st.progress(0, "æº–å‚™é–‹å§‹...")
    for i, year_val in enumerate(years_to_analyze):
        bar.progress((i + 1) / len(years_to_analyze), f"æ­£åœ¨è™•ç† {year_val} å¹´...")
        df1 = load_year_data(_base_path, s1, str(year_val))
        df2 = load_year_data(_base_path, s2, str(year_val))
        
        corr = np.nan
        pair_count = 0
        
        if df1 is not None and not df1.empty and df2 is not None and not df2.empty and param_col in df1.columns and param_col in df2.columns:
            merged = pd.merge(df1[['time', param_col]], df2[['time', param_col]], on='time', how='inner').dropna()
            pair_count = len(merged)
            if pair_count > 1:
                corr = merged.iloc[:, 1].corr(merged.iloc[:, 2])
                
        results_data.append({'å¹´ä»½': year_val, 'ç›¸é—œä¿‚æ•¸': corr, 'é…å°è³‡æ–™é»æ•¸': pair_count})
    bar.empty()
    
    results_df = pd.DataFrame(results_data)
    return results_df

@st.cache_data
def get_common_available_years(_base_path, station1, station2, all_years):
    """
    æŸ¥è©¢å…©å€‹æŒ‡å®šæ¸¬ç«™å…±åŒæ“æœ‰è³‡æ–™çš„å¹´ä»½åˆ—è¡¨ã€‚
    """
    common_years = []
    for year in all_years:
        df1_check = load_year_data(_base_path, station1, year)
        if df1_check is not None and not df1_check.empty:
            df2_check = load_year_data(_base_path, station2, year)
            if df2_check is not None and not df2_check.empty:
                common_years.append(year)
    return sorted(common_years, reverse=True)

# --- ç¹ªåœ–èˆ‡UIæ¸²æŸ“è¼”åŠ©å‡½å¼ ---
def create_download_package(files_dict):
    """
    å°‡å¤šå€‹æª”æ¡ˆå…§å®¹æ‰“åŒ…æˆä¸€å€‹ ZIP æª”ã€‚
    """
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
        for filename, content in files_dict.items():
            if isinstance(content, str):
                zf.writestr(filename, content.encode('utf-8'))
            else:
                zf.writestr(filename, content)
    return zip_buffer.getvalue()

def render_quality_pie_chart(quality_df, title):
    """æ ¹æ“šå“è³ªæ‘˜è¦DataFrameï¼Œæ¸²æŸ“åŒ…å«ç•°å¸¸å€¼çš„æ•´é«”æ•¸æ“šå“è³ªåœ“é¤…åœ–"""
    if quality_df is None or quality_df.empty or 'ç•°å¸¸å€¼' not in quality_df.columns:
        st.warning("ç„¡å“è³ªè³‡æ–™å¯ç¹ªåœ–ï¼Œæˆ–è³‡æ–™æ ¼å¼ä¸å«ç•°å¸¸å€¼è³‡è¨Šã€‚")
        return
        
    total_valid = quality_df['æœ‰æ•ˆå€¼'].sum()
    total_missing = quality_df['ç¼ºå¤±å€¼'].sum()
    total_outliers = quality_df['ç•°å¸¸å€¼'].sum()
    total_normal = max(0, total_valid - total_outliers)
    
    if total_normal + total_outliers + total_missing == 0:
        st.warning("æ²’æœ‰æ•¸æ“šå¯ä¾›ç¹ªè£½åœ“é¤…åœ–ã€‚")
        return

    pie_data = {
        'é¡åˆ¥': ['æ­£å¸¸æ•¸æ“š', 'æ½›åœ¨ç•°å¸¸å€¼', 'ç¼ºå¤±æ•¸æ“š'],
        'æ•¸é‡': [total_normal, total_outliers, total_missing]
    }
    pie_df = pd.DataFrame(pie_data)
    pie_df = pie_df[pie_df['æ•¸é‡'] > 0]
    
    if pie_df.empty:
        st.info("æ‰€æœ‰æ•¸æ“šçš†å®Œæ•´ä¸”ç„¡ç•°å¸¸å€¼ã€‚")
        return

    fig = px.pie(
        pie_df, 
        values='æ•¸é‡', 
        names='é¡åˆ¥', 
        title=title,
        hole=0.4,
        color_discrete_map={
            'æ­£å¸¸æ•¸æ“š': '#1f77b4',
            'æ½›åœ¨ç•°å¸¸å€¼': '#ff7f0e',
            'ç¼ºå¤±æ•¸æ“š': '#d62728'
        }
    )
    fig.update_traces(
        textposition='inside', 
        textinfo='percent+label', 
        pull=[0.05 if cat in ['æ½›åœ¨ç•°å¸¸å€¼', 'ç¼ºå¤±æ•¸æ“š'] else 0 for cat in pie_df['é¡åˆ¥']]
    )
    fig.update_layout(
        showlegend=True,
        margin=dict(l=0, r=0, t=40, b=0),
        legend_title_text='æ•¸æ“šé¡åˆ¥'
    )
    st.plotly_chart(fig, use_container_width=True)

def create_rose_plot(df, station_name, param_name_display, dir_col, mag_col):
    """æ ¹æ“šæ–¹å‘å’Œé‡å€¼æ•¸æ“šï¼Œå»ºç«‹ä¸€å€‹æ¥µåº§æ¨™çš„ç«ç‘°åœ–ã€‚"""
    df_plot = df[[dir_col, mag_col]].dropna()
    if df_plot.empty: return None
    bins = np.arange(-11.25, 360, 22.5)
    labels = ["åŒ—", "åŒ—åŒ—æ±", "æ±åŒ—", "æ±åŒ—æ±", "æ±", "æ±å—æ±", "æ±å—", "å—å—æ±", "å—", "å—å—è¥¿", "è¥¿å—", "è¥¿è¥¿å—", "è¥¿", "è¥¿åŒ—è¥¿", "è¥¿åŒ—", "åŒ—åŒ—è¥¿"]
    dir_binned_series = pd.cut(df_plot[dir_col] % 360, bins=bins, labels=labels, right=False)
    dir_freq = dir_binned_series.value_counts().reindex(labels, fill_value=0)
    fig = px.bar_polar(
        dir_freq, r=dir_freq.values, theta=dir_freq.index,
        title=f"{station_name} - {param_name_display}åˆ†ä½ˆç«ç‘°åœ–", template="seaborn",
        labels={'theta': 'æ–¹å‘', 'r': 'é »ç‡ (è§€æ¸¬æ¬¡æ•¸)'}, color_discrete_sequence=px.colors.sequential.Plasma_r
    )
    fig.update_layout(polar=dict(angularaxis=dict(direction="clockwise", period=360)))
    return fig

def render_advanced_analysis(merged, x_col, y_col, station1, station2):
    """æ¸²æŸ“é€²éšåˆ†æåœ–è¡¨ (Cross-correlation, Q-Q Plot)"""
    adv_col1, adv_col2 = st.columns(2)
    x_series, y_series = merged[x_col], merged[y_col]
    
    with adv_col1:
        st.subheader("æ™‚é–“å»¶é²ç›¸é—œåœ– (Cross-correlation)")
        st.caption(f"åˆ†æ {station1} çš„è¨Šè™Ÿç§»å‹•å¤šå°‘å°æ™‚å¾Œï¼Œæœƒèˆ‡ {station2} çš„è¨Šè™Ÿæœ€ç›¸é—œã€‚")
        max_lag_hours = 48
        if len(x_series) > max_lag_hours:
            x_norm = (x_series - x_series.mean()) / x_series.std()
            y_norm = (y_series - y_series.mean()) / y_series.std()
            correlation = signal.correlate(x_norm, y_norm, mode='full') / len(x_norm)
            lags = signal.correlation_lags(len(x_norm), len(y_norm), mode="full")
            
            lag_filter = (lags >= -max_lag_hours) & (lags <= max_lag_hours)
            lags, correlation = lags[lag_filter], correlation[lag_filter]

            best_lag = lags[np.argmax(np.abs(correlation))]
            best_corr = correlation[np.argmax(np.abs(correlation))]

            st.metric(f"æœ€å¤§ç›¸é—œæ€§æ™‚çš„å»¶é² (å°æ™‚)", f"{best_lag}", help=f"ç•¶ {station1} çš„æ™‚é–“åºåˆ—ç§»å‹• {best_lag} å°æ™‚å¾Œï¼Œèˆ‡ {station2} çš„ç›¸é—œä¿‚æ•¸é”åˆ°æœ€å¤§å€¼ {best_corr:.3f}ã€‚æ­£å€¼è¡¨ç¤º {station1} é ˜å…ˆï¼Œè² å€¼è¡¨ç¤ºè½å¾Œã€‚")
            
            fig_lag = px.line(x=lags, y=correlation, title=f"æ™‚é–“å»¶é²ç›¸é—œæ€§", labels={'x': 'æ™‚é–“å»¶é² (å°æ™‚)', 'y': 'æ­£è¦åŒ–ç›¸é—œä¿‚æ•¸'})
            fig_lag.add_vline(x=best_lag, line_width=2, line_dash="dash", line_color="red")
            st.plotly_chart(fig_lag, use_container_width=True)
        else:
            st.warning("æ•¸æ“šé»ä¸è¶³ï¼Œç„¡æ³•é€²è¡Œæœ‰æ„ç¾©çš„æ™‚é–“å»¶é²åˆ†æã€‚")

    with adv_col2:
        st.subheader("Q-Q åˆ†ä½åœ– (Quantile-Quantile)")
        st.caption("æ¯”è¼ƒå…©çµ„æ•¸æ“šçš„åˆ†ä½ˆå½¢ç‹€ã€‚è‹¥æ•¸æ“šé»ç·Šå¯†è²¼åˆç´…è‰²å°è§’ç·šï¼Œè¡¨ç¤ºå…©è€…åˆ†ä½ˆéå¸¸ç›¸ä¼¼ã€‚")
        quantiles = np.linspace(0.01, 0.99, 100)
        x_quantiles = mstats.mquantiles(x_series, prob=quantiles)
        y_quantiles = mstats.mquantiles(y_series, prob=quantiles)
        
        fig_qq = go.Figure()
        fig_qq.add_trace(go.Scatter(x=x_quantiles, y=y_quantiles, mode='markers', name='Quantiles'))
        fig_qq.add_trace(go.Scatter(x=[min(x_quantiles), max(x_quantiles)], y=[min(y_quantiles), max(y_quantiles)], mode='lines', name='Fit Line', line=dict(color='red', dash='dash')))
        fig_qq.update_layout(title="Q-Q åˆ†ä½åœ–", xaxis_title=f"{station1} Quantiles", yaxis_title=f"{station2} Quantiles")
        st.plotly_chart(fig_qq, use_container_width=True)

def render_linear_analysis_plots(results, station1, station2, year, param_col):
    """æ¸²æŸ“ç·šæ€§åˆ†æçš„æ‰€æœ‰åœ–è¡¨å’Œçµæœ"""
    merged = results["merged"]
    x_col, y_col = results["x_col"], results["y_col"]
    x_label = f"{station1} {PARAM_DISPLAY_NAMES.get(param_col, param_col)}{PARAM_UNITS.get(param_col, '')}"
    y_label = f"{station2} {PARAM_DISPLAY_NAMES.get(param_col, param_col)}{PARAM_UNITS.get(param_col, '')}"
    
    st.metric(f"çš®çˆ¾æ£®ç›¸é—œä¿‚æ•¸ (Pearson Correlation)", f"{results['corr']:.4f}")
    
    fig_scatter = px.scatter(
        merged, x=x_col, y=y_col, 
        trendline="ols", trendline_color_override="red", 
        marginal_x="histogram", marginal_y="histogram", 
        labels={"x": x_label, "y": y_label}, 
        title=f"{station1} vs {station2} - {PARAM_DISPLAY_NAMES.get(param_col, param_col)} è¯åˆåˆ†ä½ˆåœ– ({year}å¹´)"
    )
    fig_timeseries = px.line(merged, x='time', y=[x_col, y_col], title=f"{PARAM_DISPLAY_NAMES.get(param_col, param_col)} æ™‚åºæ¯”è¼ƒåœ–")
    fig_density = px.density_heatmap(
        merged, x=x_col, y=y_col, 
        labels={"x": x_label, "y": y_label}, 
        title=f"{station1} vs {station2} - {PARAM_DISPLAY_NAMES.get(param_col, param_col)} æ•¸æ“šå¯†åº¦åœ– ({year}å¹´)"
    )

    tabs = st.tabs(["è¯åˆåˆ†ä½ˆåœ–", "æ™‚åºåœ–", "å¯†åº¦åœ–", "é€²éšåˆ†æ", "è©³ç´°æ•¸æ“š", "ä¸‹è¼‰å°ˆå€"])
    with tabs[0]:
        st.info("æ­¤åœ–é¡¯ç¤ºå…©æ¸¬ç«™æ•¸æ“šçš„ç›´æ¥é—œä¿‚ï¼Œä¸¦åœ¨åœ–è¡¨é‚Šç·£é™„åŠ äº†å„è‡ªæ•¸æ“šçš„ç›´æ–¹åœ–ã€‚")
        st.plotly_chart(fig_scatter, use_container_width=True)
        with st.container(border=True):
            st.markdown("##### ğŸ“ˆ å›æ­¸åˆ†æçµæœ")
            st.latex(fr''' y = {results["slope"]:.4f}x {'+' if results["intercept"] >= 0 else ''} {results["intercept"]:.4f} \quad (R^2 = {results["r_squared"]:.4f})''')
    with tabs[1]:
        st.plotly_chart(fig_timeseries, use_container_width=True)
    with tabs[2]:
        st.plotly_chart(fig_density, use_container_width=True)
    with tabs[3]:
        render_advanced_analysis(merged, x_col, y_col, station1, station2)
    with tabs[4]:
        st.dataframe(merged, use_container_width=True)
    with tabs[5]:
        st.subheader("ğŸ“¥ ä¸‹è¼‰åˆ†æç”¢å‡º")
        prefix = f"corr_linear_{station1}_{station2}_{param_col}_{year}"
        summary_content = f"åˆ†æå ±å‘Š\n{'='*20}\næ¸¬ç«™ A: {station1}\næ¸¬ç«™ B: {station2}\nå¹´ä»½: {year}\nåƒæ•¸: {PARAM_DISPLAY_NAMES.get(param_col, param_col)}\n\nçš®çˆ¾æ£®ç›¸é—œä¿‚æ•¸: {results['corr']:.4f}\nå›æ­¸ç·š: y = {results['slope']:.4f}x + {results['intercept']:.4f}\nR-squared: {results['r_squared']:.4f}"
        
        dl_c1, dl_c2 = st.columns(2)
        with dl_c1:
            st.download_button("ğŸ“¥ ä¸‹è¼‰åœ–è¡¨ (HTML)", fig_scatter.to_html(), f"{prefix}_chart.html", "text/html", use_container_width=True, key=f"dl_html_{prefix}")
            st.download_button("ğŸ“¥ ä¸‹è¼‰æ•¸æ“š (CSV)", convert_df_to_csv(merged), f"{prefix}_data.csv", "text/csv", use_container_width=True, key=f"dl_csv_{prefix}")
        with dl_c2:
            st.download_button("ğŸ“¥ ä¸‹è¼‰å ±å‘Š (TXT)", summary_content, f"{prefix}_summary.txt", "text/plain", use_container_width=True, key=f"dl_txt_{prefix}")
            zip_buffer = create_download_package({f"{prefix}_chart.html": fig_scatter.to_html(), f"{prefix}_summary.txt": summary_content, f"{prefix}_data.csv": convert_df_to_csv(merged)})
            st.download_button("ğŸ“¦ ä¸€éµæ‰“åŒ…ä¸‹è¼‰ (.zip)", zip_buffer, f"{prefix}_package.zip", "application/zip", use_container_width=True, key=f"dl_zip_{prefix}")

def render_circular_analysis_plots(results, station1, station2, year, param_col):
    """æ¸²æŸ“æ–¹å‘æ€§åˆ†æçš„æ‰€æœ‰åœ–è¡¨å’Œçµæœ"""
    merged_uv = results["merged"]
    st.info("æ–¹å‘æ€§åƒæ•¸æ˜¯é€éè¨ˆç®—å…¶U/Våˆ†é‡çš„ç›¸é—œæ€§ä¾†é€²è¡Œè©•ä¼°ã€‚")
    c1, c2 = st.columns(2)
    c1.metric("Uåˆ†é‡ (æ±è¥¿å‘) ç›¸é—œä¿‚æ•¸", f"{results['corr_u']:.4f}")
    c2.metric("Våˆ†é‡ (å—åŒ—å‘) ç›¸é—œä¿‚æ•¸", f"{results['corr_v']:.4f}")
    
    p_name_disp, mag_col = PARAM_DISPLAY_NAMES.get(param_col, param_col), results["mag_col"]
    rose1_fig = create_rose_plot(results["df1_raw"], station1, p_name_disp, param_col, mag_col)
    rose2_fig = create_rose_plot(results["df2_raw"], station2, p_name_disp, param_col, mag_col)
    fig_u = px.scatter(merged_uv, x=f'u_{station1}', y=f'u_{station2}', trendline="ols", title=f"Uåˆ†é‡ç›¸é—œæ€§ (R={results['corr_u']:.3f})")
    fig_v = px.scatter(merged_uv, x=f'v_{station1}', y=f'v_{station2}', trendline="ols", title=f"Våˆ†é‡ç›¸é—œæ€§ (R={results['corr_v']:.3f})")

    tabs = st.tabs(["æ–¹å‘ç«ç‘°åœ–", "U/Våˆ†é‡åœ–", "è©³ç´°æ•¸æ“š", "ä¸‹è¼‰å°ˆå€"])
    with tabs[0]:
        r_col1, r_col2 = st.columns(2)
        if rose1_fig: r_col1.plotly_chart(rose1_fig, use_container_width=True)
        else: r_col1.warning(f"{station1} ç„¡æ³•ç¹ªè£½ç«ç‘°åœ–")
        if rose2_fig: r_col2.plotly_chart(rose2_fig, use_container_width=True)
        else: r_col2.warning(f"{station2} ç„¡æ³•ç¹ªè£½ç«ç‘°åœ–")
    with tabs[1]:
        uv_col1, uv_col2 = st.columns(2)
        uv_col1.plotly_chart(fig_u, use_container_width=True)
        uv_col2.plotly_chart(fig_v, use_container_width=True)
    with tabs[2]:
        st.dataframe(results["merged"], use_container_width=True)
    with tabs[3]:
        st.subheader("ğŸ“¥ ä¸‹è¼‰åˆ†æç”¢å‡º")
        prefix = f"corr_circular_{station1}_{station2}_{param_col}_{year}"
        summary_content = f"åˆ†æå ±å‘Š\n{'='*20}\næ¸¬ç«™ A: {station1}\næ¸¬ç«™ B: {station2}\nå¹´ä»½: {year}\nåƒæ•¸: {p_name_disp}\n\nUåˆ†é‡ç›¸é—œä¿‚æ•¸: {results['corr_u']:.4f}\nVåˆ†é‡ç›¸é—œä¿‚æ•¸: {results['corr_v']:.4f}"
        html_content = f"<html><head><title>{prefix}</title></head><body><h1>U-Våˆ†é‡åœ–</h1>" + fig_u.to_html(full_html=False, include_plotlyjs='cdn') + fig_v.to_html(full_html=False, include_plotlyjs=False) + "</body></html>"
        
        dl_c1, dl_c2 = st.columns(2)
        with dl_c1:
            st.download_button("ğŸ“¥ ä¸‹è¼‰åœ–è¡¨ (HTML)", html_content, f"{prefix}_charts.html", "text/html", use_container_width=True, key=f"dl_html_{prefix}")
            st.download_button("ğŸ“¥ ä¸‹è¼‰æ•¸æ“š (CSV)", convert_df_to_csv(results["merged"]), f"{prefix}_data.csv", "text/csv", use_container_width=True, key=f"dl_csv_{prefix}")
        with dl_c2:
            st.download_button("ğŸ“¥ ä¸‹è¼‰å ±å‘Š (TXT)", summary_content, f"{prefix}_summary.txt", "text/plain", use_container_width=True, key=f"dl_txt_{prefix}")
            zip_files = {
                f"{prefix}_uv_charts.html": html_content, 
                f"{prefix}_summary.txt": summary_content, 
                f"{prefix}_data.csv": convert_df_to_csv(results["merged"])
            }
            if rose1_fig: zip_files[f"{prefix}_{station1}_rose.html"] = rose1_fig.to_html()
            if rose2_fig: zip_files[f"{prefix}_{station2}_rose.html"] = rose2_fig.to_html()
            zip_buffer = create_download_package(zip_files)
            st.download_button("ğŸ“¦ ä¸€éµæ‰“åŒ…ä¸‹è¼‰ (.zip)", zip_buffer, f"{prefix}_package.zip", "application/zip", use_container_width=True, key=f"dl_zip_{prefix}")

def render_trend_chart_and_downloads(results_df, s1, s2, param_disp, param_col, start_y, end_y, chart_type):
    """æ¸²æŸ“è¶¨å‹¢åœ–ä¸¦æä¾›æ¨™æº–åŒ–çš„ä¸‹è¼‰é¸é …"""
    st.subheader("ğŸ“ˆ è¶¨å‹¢åœ–èˆ‡ä¸‹è¼‰")
    title = f"{s1} vs {s2} - {param_disp} é€å¹´ç›¸é—œä¿‚æ•¸ ({start_y}-{end_y})"
    plot_df = results_df.dropna(subset=['ç›¸é—œä¿‚æ•¸'])
    
    if plot_df.empty:
        st.warning("ç„¡è¶³å¤ æ•¸æ“šç¹ªè£½è¶¨å‹¢åœ–ã€‚")
        return

    if chart_type == 'é•·æ¢åœ–':
        fig = px.bar(plot_df, x='å¹´ä»½', y='ç›¸é—œä¿‚æ•¸', text_auto='.3f', title=title)
    elif chart_type == 'é¢ç©åœ–':
        fig = px.area(plot_df, x='å¹´ä»½', y='ç›¸é—œä¿‚æ•¸', markers=True, title=title)
    elif chart_type == 'æ•£ä½ˆåœ– (å«è¶¨å‹¢ç·š)':
        plot_df['å¹´ä»½_num'] = pd.to_numeric(plot_df['å¹´ä»½'])
        fig = px.scatter(plot_df, x='å¹´ä»½_num', y='ç›¸é—œä¿‚æ•¸', trendline="ols", title=title, labels={"å¹´ä»½_num": "å¹´ä»½"})
    else:
        fig = px.line(plot_df, x='å¹´ä»½', y='ç›¸é—œä¿‚æ•¸', markers=True, text=plot_df['ç›¸é—œä¿‚æ•¸'].apply(lambda x: f'{x:.3f}'), title=title)
    
    fig.update_xaxes(type='category')
    st.plotly_chart(fig, use_container_width=True)

    if chart_type == 'æ•£ä½ˆåœ– (å«è¶¨å‹¢ç·š)' and len(plot_df) >= 2:
        slope, intercept, r_value, _, _ = linregress(plot_df['å¹´ä»½_num'], plot_df['ç›¸é—œä¿‚æ•¸'])
        with st.container(border=True):
            st.markdown("##### ğŸ“ˆ è¶¨å‹¢ç·šåˆ†æ")
            st.latex(fr''' y = {slope:.4f}x {'+' if intercept >= 0 else ''} {intercept:.4f} \quad (R^2 = {r_value**2:.4f})''')
    
    st.markdown("---")
    st.subheader("ğŸ“¥ ä¸‹è¼‰åˆ†æç”¢å‡º")
    prefix = f"trend_{s1}_{s2}_{param_col}_{start_y}-{end_y}"
    summary_content = f"åˆ†æå ±å‘Š\n{'='*20}\næ¸¬ç«™ A: {s1}\næ¸¬ç«™ B: {s2}\nå¹´ä»½: {start_y}-{end_y}\nåƒæ•¸: {param_disp}\n\nå¹³å‡ç›¸é—œä¿‚æ•¸: {plot_df['ç›¸é—œä¿‚æ•¸'].mean():.4f}"
    
    dl_c1, dl_c2 = st.columns(2)
    with dl_c1:
        st.download_button("ğŸ“¥ ä¸‹è¼‰åœ–è¡¨ (HTML)", fig.to_html(), f"{prefix}_chart.html", "text/html", use_container_width=True, key=f"dl_html_{prefix}")
        st.download_button("ğŸ“¥ ä¸‹è¼‰æ•¸æ“š (CSV)", convert_df_to_csv(results_df), f"{prefix}_data.csv", "text/csv", use_container_width=True, key=f"dl_csv_{prefix}")
    with dl_c2:
        st.download_button("ğŸ“¥ ä¸‹è¼‰å ±å‘Š (TXT)", summary_content, f"{prefix}_summary.txt", "text/plain", use_container_width=True, key=f"dl_txt_{prefix}")
        zip_buffer = create_download_package({f"{prefix}_chart.html": fig.to_html(), f"{prefix}_summary.txt": summary_content, f"{prefix}_data.csv": convert_df_to_csv(results_df)})
        st.download_button("ğŸ“¦ ä¸€éµæ‰“åŒ…ä¸‹è¼‰ (.zip)", zip_buffer, f"{prefix}_package.zip", "application/zip", use_container_width=True, key=f"dl_zip_{prefix}")


# --- ä¸»åŠŸèƒ½å‡½å¼ ---
def run_single_year_analysis(locations, available_years, base_data_path):
    """åŸ·è¡Œå–®å¹´åº¦è©³ç´°æ¯”è¼ƒçš„ UI èˆ‡é‚è¼¯"""
    st.header("å–®å¹´åº¦è©³ç´°æ¯”è¼ƒ")
    st.write("æ¯”è¼ƒå…©å€‹æ¸¬ç«™åœ¨ç‰¹å®šæ™‚é–“ç¯„åœå…§çš„æ•¸æ“šç›¸é—œæ€§ï¼Œä¸¦æª¢è¦–å…¶æ•¸æ“šå“è³ªã€‚")
    
    analysis_params = {}
    can_analyze = False

    with st.container(border=True):
        st.subheader("âš™ï¸ åˆ†æè¨­å®š")
        col1, col2, col3 = st.columns(3)
        station1 = col1.selectbox('é¸æ“‡æ¸¬ç«™ A:', options=locations, key='s1_single', format_func=get_station_name_from_id)
        station2 = col2.selectbox('é¸æ“‡æ¸¬ç«™ B:', options=locations, key='s2_single', index=min(1, len(locations)-1), format_func=get_station_name_from_id)
        station1_name, station2_name = get_station_name_from_id(station1), get_station_name_from_id(station2)

        # <<< ä¿®æ”¹é‡é» 1: å³æ™‚æª¢æŸ¥æ¸¬ç«™é¸æ“‡ >>>
        # åœ¨é¸æ“‡æ¸¬ç«™å¾Œç«‹å³æª¢æŸ¥æ˜¯å¦ç›¸åŒï¼Œä¸¦æä¾›å³æ™‚åé¥‹ï¼Œè€Œéç­‰åˆ°æŒ‰ä¸‹æŒ‰éˆ•å¾Œã€‚
        if station1 == station2:
            col3.selectbox('é¸æ“‡å¹´ä»½:', ["è«‹å…ˆé¸æ“‡ä¸åŒæ¸¬ç«™"], disabled=True, key='y_single_disabled_same')
            st.warning("è«‹é¸æ“‡å…©å€‹ä¸åŒçš„æ¸¬ç«™ä»¥é€²è¡Œæ¯”è¼ƒã€‚")
            st.selectbox('é¸æ“‡åƒæ•¸:', ["---"], disabled=True, key='p_single_disabled_same')
            can_analyze = False
        else:
            with st.spinner(f"æ­£åœ¨æŸ¥è©¢ {station1_name} èˆ‡ {station2_name} çš„å…±åŒå¯ç”¨å¹´ä»½..."):
                common_years = get_common_available_years(base_data_path, station1, station2, available_years)

            if not common_years:
                col3.selectbox('é¸æ“‡å¹´ä»½:', ["ç„¡å…±åŒå¹´ä»½è³‡æ–™"], disabled=True, key='y_single_disabled_no_data')
                st.warning(f"âš ï¸ **{station1_name}** èˆ‡ **{station2_name}** æ²’æœ‰å…±åŒçš„è³‡æ–™å¹´ä»½ï¼Œè«‹é‡æ–°é¸æ“‡æ¸¬ç«™ã€‚")
                st.selectbox('é¸æ“‡åƒæ•¸:', ["---"], disabled=True, key='p_single_disabled_no_data')
                can_analyze = False
            else:
                # <<< ä¿®æ”¹é‡é» 2: åªæœ‰åœ¨æ¢ä»¶æ»¿è¶³æ™‚æ‰é¡¯ç¤ºå¯ç”¨é¸é … >>>
                # å°‡å¹´ä»½å’Œåƒæ•¸é¸æ“‡æ”¾åœ¨ "else" å€å¡Šå…§ï¼Œç¢ºä¿åªæœ‰åœ¨æ‰¾åˆ°å…±åŒå¹´ä»½æ™‚æ‰è®“ä½¿ç”¨è€…æ“ä½œã€‚
                year = col3.selectbox('é¸æ“‡å¹´ä»½:', options=common_years, index=0, key='y_single_dynamic')
                param_options_single = {
                    "ç¤ºæ€§æ³¢é«˜": ("Wave_Height_Significant", "linear"), "å¹³å‡æ³¢é€±æœŸ": ("Wave_Mean_Period", "linear"),
                    "æ³¢æµªå°–å³°é€±æœŸ": ("Wave_Peak_Period", "linear"), "é¢¨é€Ÿ": ("Wind_Speed", "linear"),
                    "é™£é¢¨é¢¨é€Ÿ": ("Wind_Gust_Speed", "linear"), "æ°£æº«": ("Air_Temperature", "linear"),
                    "æµ·é¢æº«åº¦": ("Sea_Temperature", "linear"), "æ°£å£“": ("Air_Pressure", "linear"),
                    "---": (None, None), "é¢¨å‘": ("Wind_Direction", "circular"), "æ³¢å‘": ("Wave_Main_Direction", "circular"),
                }
                selected_param_display = st.selectbox('é¸æ“‡åƒæ•¸:', options=param_options_single.keys(), key='p_single')
                param_col, analysis_type = param_options_single[selected_param_display]
                
                # åªæœ‰åœ¨æ‰€æœ‰æ¢ä»¶éƒ½æ»¿è¶³æ™‚ï¼Œæ‰è¨­å®šåˆ†æåƒæ•¸ä¸¦å•Ÿç”¨æŒ‰éˆ•
                if param_col:
                    analysis_params = {
                        "station1": station1_name, "station2": station2_name, "year": year, 
                        "param_col": param_col, "analysis_type": analysis_type
                    }
                    can_analyze = True

    # æ ¹æ“š can_analyze çš„ç‹€æ…‹æ±ºå®šæŒ‰éˆ•æ˜¯å¦å¯è¢«é»æ“Š
    if st.button("ğŸ“Š è¨ˆç®—å–®å¹´åº¦ç›¸é—œæ€§", key='btn_single', use_container_width=True, disabled=not can_analyze):
        p = analysis_params
        # <<< ä¿®æ”¹é‡é» 3: ç§»é™¤å¤šé¤˜çš„æª¢æŸ¥ >>>
        # å› ç‚ºä¸Šé¢çš„UIé‚è¼¯å·²ç¶“ç¢ºä¿äº† `can_analyze` ç‚º True æ™‚ï¼Œæ¸¬ç«™ä¸åŒä¸”åƒæ•¸æœ‰æ•ˆï¼Œ
        # æ‰€ä»¥é€™è£¡ä¸å†éœ€è¦ `if p.get("station1") == p.get("station2")` çš„æª¢æŸ¥ã€‚

        with st.spinner(f'æ­£åœ¨è¼‰å…¥èˆ‡åˆ†æ {p["station1"]} vs {p["station2"]} åœ¨ {p["year"]}å¹´ çš„è³‡æ–™...'):
            results = calculate_single_year_correlation(base_data_path, p["station1"], p["station2"], p["year"], p["param_col"], p["analysis_type"])

        with st.expander("ğŸ“Š é»æ­¤æŸ¥çœ‹è¼¸å…¥æ•¸æ“šçš„å“è³ªæ¦‚è¦½", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"##### {p['station1']} ({p['year']}å¹´) æ•¸æ“šå“è³ª")
                if results["quality1"] is not None and not results["quality1"].empty:
                    st.dataframe(
                        results["quality1"].style
                            .background_gradient(cmap='Greens', subset=['å®Œæ•´åº¦ (%)'])
                            .format({"å®Œæ•´åº¦ (%)": "{:.2f}%", "ç•°å¸¸å€¼": "{:d}"}),
                        use_container_width=True
                    )
                    render_quality_pie_chart(results["quality1"], f"{p['station1']} æ•´é«”å“è³ª")
                else:
                    st.warning(f"ç„¡æ³•è¼‰å…¥æˆ–åˆ†æ {p['station1']} çš„æ•¸æ“šå“è³ªã€‚")
            with col2:
                st.markdown(f"##### {p['station2']} ({p['year']}å¹´) æ•¸æ“šå“è³ª")
                if results["quality2"] is not None and not results["quality2"].empty:
                    st.dataframe(
                        results["quality2"].style
                            .background_gradient(cmap='Greens', subset=['å®Œæ•´åº¦ (%)'])
                            .format({"å®Œæ•´åº¦ (%)": "{:.2f}%", "ç•°å¸¸å€¼": "{:d}"}),
                        use_container_width=True
                    )
                    render_quality_pie_chart(results["quality2"], f"{p['station2']} æ•´é«”å“è³ª")
                else:
                    st.warning(f"ç„¡æ³•è¼‰å…¥æˆ–åˆ†æ {p['station2']} çš„æ•¸æ“šå“è³ªã€‚")
        st.markdown("---")
        
        if "error" in results:
            st.error(results["error"])
        else:
            st.markdown(f"#### ğŸ” åˆ†æçµæœ: **{p['station1']}** vs. **{p['station2']}** ({p['year']}å¹´) | **{PARAM_DISPLAY_NAMES.get(p['param_col'], p['param_col'])}**")
            if results["type"] == 'linear':
                render_linear_analysis_plots(results, p["station1"], p["station2"], p["year"], p["param_col"])
            elif results["type"] == 'circular':
                render_circular_analysis_plots(results, p["station1"], p["station2"], p["year"], p["param_col"])

def run_yearly_trend_analysis(locations, available_years, base_data_path):
    """åŸ·è¡Œé€å¹´è¶¨å‹¢æ¯”è¼ƒçš„ UI èˆ‡é‚è¼¯"""
    st.header("é€å¹´è¶¨å‹¢æ¯”è¼ƒ")
    st.write("æ¯”è¼ƒå…©å€‹æ¸¬ç«™ç‰¹å®šåƒæ•¸çš„ç›¸é—œæ€§ï¼Œåœ¨é€£çºŒå¹´ä»½ä¸­çš„è®ŠåŒ–è¶¨å‹¢ã€‚")

    analysis_params = {}
    can_analyze = False

    with st.container(border=True):
        st.subheader("âš™ï¸ åˆ†æè¨­å®š")
        col1, col2 = st.columns(2)
        s1 = col1.selectbox('æ¸¬ç«™ A:', locations, key='s1_trend', format_func=get_station_name_from_id)
        s2 = col1.selectbox('æ¸¬ç«™ B:', locations, key='s2_trend', index=min(1, len(locations)-1), format_func=get_station_name_from_id)
        s1_name, s2_name = get_station_name_from_id(s1), get_station_name_from_id(s2)
        
        param_map_trend = {
            "ç¤ºæ€§æ³¢é«˜": "Wave_Height_Significant", "å¹³å‡æ³¢é€±æœŸ": "Wave_Mean_Period", "æ³¢æµªå°–å³°é€±æœŸ": "Wave_Peak_Period",
            "é¢¨é€Ÿ": "Wind_Speed", "é™£é¢¨é¢¨é€Ÿ": "Wind_Gust_Speed", "æ°£æº«": "Air_Temperature",
            "æµ·é¢æº«åº¦": "Sea_Temperature", "æ°£å£“": "Air_Pressure"
        }
        param_disp = col2.selectbox('åƒæ•¸ (åƒ…é™ç´”é‡):', param_map_trend.keys(), key='p_trend')
        param_col = param_map_trend[param_disp]
        
        # <<< ä¿®æ”¹é‡é» 1: åŒæ¨£é€²è¡Œå³æ™‚æª¢æŸ¥ >>>
        if s1 == s2:
            st.warning("è«‹é¸æ“‡å…©å€‹ä¸åŒçš„æ¸¬ç«™ä»¥é€²è¡Œæ¯”è¼ƒã€‚")
            st.select_slider('é¸æ“‡å¹´ä»½ç¯„åœ:', ["è«‹å…ˆé¸æ“‡ä¸åŒæ¸¬ç«™"], disabled=True, key='y_slider_disabled_same')
            can_analyze = False
        else:
            with st.spinner(f"æ­£åœ¨æŸ¥è©¢ {s1_name} èˆ‡ {s2_name} çš„å…±åŒå¯ç”¨å¹´ä»½..."):
                common_years = get_common_available_years(base_data_path, s1, s2, available_years)

            sorted_int_years = sorted([int(y) for y in common_years])

            if not sorted_int_years:
                st.select_slider('é¸æ“‡å¹´ä»½ç¯„åœ:', ["ç„¡å…±åŒå¹´ä»½è³‡æ–™"], disabled=True, key='y_slider_disabled_no_data')
                st.warning(f"âš ï¸ **{s1_name}** èˆ‡ **{s2_name}** æ²’æœ‰å…±åŒçš„è³‡æ–™å¹´ä»½ï¼Œè«‹é‡æ–°é¸æ“‡æ¸¬ç«™ã€‚")
                can_analyze = False
            else:
                # <<< ä¿®æ”¹é‡é» 4: å„ªåŒ–å¹´ä»½æ»‘æ¡¿çš„é è¨­å€¼é¸å–é‚è¼¯ >>>
                # ç¢ºä¿åœ¨åªæœ‰ä¸€å€‹å…±åŒå¹´ä»½æ™‚ä¸æœƒå‡ºéŒ¯ï¼Œä¸¦æä¾›æ›´åˆç†çš„é è¨­ç¯„åœã€‚
                default_end = sorted_int_years[-1]
                # é è¨­èµ·å§‹å€¼ç‚ºå€’æ•¸ç¬¬äºŒå¹´ï¼Œä½†è‹¥ç¸½å¹´æ•¸ä¸è¶³å‰‡å¾ç¬¬ä¸€å¹´é–‹å§‹
                default_start_index = max(0, len(sorted_int_years) - 2)
                default_start = sorted_int_years[default_start_index]

                start_y, end_y = st.select_slider(
                    'é¸æ“‡å¹´ä»½ç¯„åœ:', 
                    options=sorted_int_years, 
                    value=(default_start, default_end), 
                    key='y_slider_dynamic'
                )
                chart_type = st.selectbox('åœ–è¡¨é¡å‹:', ['é•·æ¢åœ–', 'æŠ˜ç·šåœ–', 'é¢ç©åœ–', 'æ•£ä½ˆåœ– (å«è¶¨å‹¢ç·š)'], key='chart_type')
                
                analysis_params = {
                    "s1": s1_name, "s2": s2_name, "param_col": param_col, "param_disp": param_disp,
                    "start_y": start_y, "end_y": end_y, "chart_type": chart_type
                }
                can_analyze = True

    if st.button("ğŸ“ˆ è¨ˆç®—é€å¹´ç›¸é—œæ€§", key='btn_trend', use_container_width=True, disabled=not can_analyze):
        p = analysis_params
        # åŒæ¨£åœ°ï¼Œé€™è£¡ä¸å†éœ€è¦æª¢æŸ¥ s1 == s2

        results_df = calculate_yearly_trend(base_data_path, p["s1"], p["s2"], p["param_col"], p["start_y"], p["end_y"])
        st.success("è¨ˆç®—å®Œæˆï¼")
        
        if results_df['ç›¸é—œä¿‚æ•¸'].dropna().empty:
            st.warning("åœ¨æŒ‡å®šçš„å¹´ä»½ç¯„åœå…§ï¼Œæ²’æœ‰è¶³å¤ çš„æœ‰æ•ˆç›¸é—œä¿‚æ•¸æ•¸æ“šå¯ä¾›é¡¯ç¤ºã€‚")
            st.stop()
            
        results_df['å¹´ä»½'] = results_df['å¹´ä»½'].astype(str)
        st.markdown(f"#### ğŸ” åˆ†æçµæœ: **{p['s1']}** vs. **{p['s2']}** ({p['start_y']} - {p['end_y']}å¹´) | **{p['param_disp']}**")

        tab_chart, tab_data, tab_quality = st.tabs(["ğŸ“ˆ è¶¨å‹¢åœ–èˆ‡ä¸‹è¼‰", "ğŸ”¢ é€å¹´æ•¸æ“š", "ğŸ“Š æ•¸æ“šå“è³ªæ¦‚è¦½"])
        
        with tab_chart:
            render_trend_chart_and_downloads(results_df, p['s1'], p['s2'], p['param_disp'], p['param_col'], p['start_y'], p['end_y'], p['chart_type'])
        with tab_data:
            st.caption("ä»¥ä¸‹ç‚ºé€å¹´è¨ˆç®—å‡ºçš„ç›¸é—œä¿‚æ•¸èˆ‡ç”¨æ–¼è¨ˆç®—çš„è³‡æ–™é»æ•¸ï¼š")
            st.dataframe(results_df[['å¹´ä»½', 'ç›¸é—œä¿‚æ•¸', 'é…å°è³‡æ–™é»æ•¸']].style.format({'ç›¸é—œä¿‚æ•¸': "{:.4f}"}), use_container_width=True)
        with tab_quality:
            st.info("æ­¤åœ–è¡¨é¡¯ç¤ºæ¯å¹´ç”¨æ–¼è¨ˆç®—ç›¸é—œæ€§çš„æˆå°æ•¸æ“šé»æ•¸é‡ã€‚æ•¸é‡éå°‘å¯èƒ½ä»£è¡¨è©²å¹´åº¦çš„ç›¸é—œä¿‚æ•¸å¯ä¿¡åº¦è¼ƒä½ã€‚")
            fig_quality = px.bar(
                results_df, 
                x='å¹´ä»½', 
                y='é…å°è³‡æ–™é»æ•¸',
                title='æ¯å¹´ç”¨æ–¼è¨ˆç®—ç›¸é—œæ€§çš„è³‡æ–™é»æ•¸é‡',
                labels={'é…å°è³‡æ–™é»æ•¸': 'æˆå°è³‡æ–™é»æ•¸é‡ (ç­†)', 'å¹´ä»½': 'å¹´ä»½'},
                text_auto=True
            )
            st.plotly_chart(fig_quality, use_container_width=True)

def main():
    """ä¸»å‡½æ•¸ï¼Œæ ¹æ“šé¸æ“‡çš„æ¨¡å¼èª¿ç”¨å°æ‡‰çš„åˆ†æå‡½å¼"""
    # æ¨¡æ“¬å¾ä¸»é é¢è¼‰å…¥ session state
    if 'locations' not in st.session_state:
        st.session_state.locations = ['StationA', 'StationB', 'StationC']
        st.session_state.available_years = ['2021', '2022', '2023']
        st.session_state.base_data_path = '.'
        st.info("åµæ¸¬åˆ°æ¸¬è©¦æ¨¡å¼ï¼Œæ­£åœ¨ä½¿ç”¨ç¯„ä¾‹è³‡æ–™ã€‚")

    locations = st.session_state.get('locations', [])
    base_data_path = st.session_state.get('base_data_path', '')
    available_years = st.session_state.get('available_years', [])

    if not all([locations, base_data_path, available_years]):
        st.warning("ç¼ºå°‘å¿…è¦çš„è¨­å®šè³‡æ–™ã€‚è«‹è¿”å›ä¸»é é¢è¼‰å…¥æ¸¬ç«™åˆ—è¡¨ã€è³‡æ–™è·¯å¾‘å’Œå¯ç”¨å¹´ä»½ã€‚")
        return

    analysis_mode = st.radio(
        "é¸æ“‡åˆ†ææ¨¡çµ„:", 
        ("å–®å¹´åº¦è©³ç´°æ¯”è¼ƒ", "é€å¹´è¶¨å‹¢æ¯”è¼ƒ"), 
        horizontal=True, 
        key='main_mode'
    )
    st.markdown("---")

    if analysis_mode == "å–®å¹´åº¦è©³ç´°æ¯”è¼ƒ":
        run_single_year_analysis(locations, available_years, base_data_path)
    elif analysis_mode == "é€å¹´è¶¨å‹¢æ¯”è¼ƒ":
        run_yearly_trend_analysis(locations, available_years, base_data_path)

if __name__ == "__main__":
    main()
